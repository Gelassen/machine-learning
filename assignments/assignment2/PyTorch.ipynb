{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.2 - Введение в PyTorch\n",
    "\n",
    "Для этого задания потребуется установить версию PyTorch 1.0\n",
    "\n",
    "https://pytorch.org/get-started/locally/\n",
    "\n",
    "В этом задании мы познакомимся с основными компонентами PyTorch и натренируем несколько небольших моделей.<br>\n",
    "GPU нам пока не понадобится.\n",
    "\n",
    "Основные ссылки:  \n",
    "https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html  \n",
    "https://pytorch.org/docs/stable/nn.html  \n",
    "https://pytorch.org/docs/stable/torchvision/index.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, Sampler\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как всегда, начинаем с загрузки данных\n",
    "\n",
    "PyTorch поддерживает загрузку SVHN из коробки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# First, lets load the dataset\n",
    "data_train = dset.SVHN('./data/', split='train',\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                                               std=[0.20,0.20,0.20])                           \n",
    "                       ])\n",
    "                      )\n",
    "data_test = dset.SVHN('./data/', split='test', \n",
    "                      transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                                               std=[0.20,0.20,0.20])                           \n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы разделим данные на training и validation с использованием классов `SubsetRandomSampler` и `DataLoader`.\n",
    "\n",
    "`DataLoader` подгружает данные, предоставляемые классом `Dataset`, во время тренировки и группирует их в батчи.\n",
    "Он дает возможность указать `Sampler`, который выбирает, какие примеры из датасета использовать для тренировки. Мы используем это, чтобы разделить данные на training и validation.\n",
    "\n",
    "Подробнее: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 64\n",
    "\n",
    "data_size = data_train.data.shape[0]\n",
    "validation_split = .2\n",
    "split = int(np.floor(validation_split * data_size))\n",
    "indices = list(range(data_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
    "                                         sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашей задаче мы получаем на вход изображения, но работаем с ними как с одномерными массивами. Чтобы превратить многомерный массив в одномерный, мы воспользуемся очень простым вспомогательным модулем `Flattener`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVHN data sample shape:  torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "sample, label = data_train[0]\n",
    "print(\"SVHN data sample shape: \", sample.shape)\n",
    "# As you can see, the data is shaped like an image\n",
    "\n",
    "# We'll use a special helper module to shape it into a tensor\n",
    "class Flattener(nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size, *_ = x.shape\n",
    "        return x.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И наконец, мы создаем основные объекты PyTorch:\n",
    "- `nn_model` - собственно, модель с нейросетью\n",
    "- `loss` - функцию ошибки, в нашем случае `CrossEntropyLoss`\n",
    "- `optimizer` - алгоритм оптимизации, в нашем случае просто `SGD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_model = nn.Sequential(\n",
    "            Flattener(),\n",
    "            nn.Linear(3*32*32, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 10), \n",
    "         )\n",
    "nn_model.type(torch.FloatTensor)\n",
    "\n",
    "# We will minimize cross-entropy between the ground truth and\n",
    "# network predictions using an SGD optimizer\n",
    "loss = nn.CrossEntropyLoss().type(torch.FloatTensor)\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr=1e-2, weight_decay=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренируем!\n",
    "\n",
    "Ниже приведена функция `train_model`, реализующая основной цикл тренировки PyTorch.\n",
    "\n",
    "Каждую эпоху эта функция вызывает функцию `compute_accuracy`, которая вычисляет точность на validation, эту последнюю функцию предлагается реализовать вам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs\\anaconda\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:118: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.836707, Train accuracy: 0.399669, Val accuracy: 0.539485\n",
      "Average loss: 1.522475, Train accuracy: 0.562605, Val accuracy: 0.562351\n",
      "Average loss: 1.496053, Train accuracy: 0.572894, Val accuracy: 0.576957\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# This is how to implement the same main train loop in PyTorch. Pretty easy, right?\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs, step_size=2, gamma=0.1):    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    scheduler = StepLR(optimizer, step_size, gamma)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for i_step, (x, y) in enumerate(train_loader):\n",
    "            prediction = model(x)    \n",
    "            loss_value = loss(prediction, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y)\n",
    "            total_samples += y.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / (i_step + 1)\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader)\n",
    "        \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
    "        \n",
    "    return loss_history, train_history, val_history\n",
    "        \n",
    "def compute_accuracy(model, loader):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the dataset wrapped in a loader\n",
    "    \n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    model.eval() # Evaluation mode\n",
    "    # TODO: Implement the inference of the model on all of the batches from loader,\n",
    "    #       and compute the overall accuracy.\n",
    "    # Hint: PyTorch has the argmax function!\n",
    "    \n",
    "    # raise Exception(\"Not implemented\")\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for x, y in loader:\n",
    "\n",
    "        prediction = model(x)\n",
    "        \n",
    "        indices =  torch.argmax(prediction, dim=1)\n",
    "        \n",
    "        correct += (indices == y).sum()\n",
    "        \n",
    "        total += y.size(0)\n",
    "        \n",
    "    return np.true_divide(correct, total)\n",
    "\n",
    "loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## После основного цикла\n",
    "\n",
    "Посмотрим на другие возможности и оптимизации, которые предоставляет PyTorch.\n",
    "\n",
    "Добавьте еще один скрытый слой размера 100 нейронов к модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.161402, Train accuracy: 0.210013, Val accuracy: 0.257662\n",
      "Average loss: 2.034466, Train accuracy: 0.264717, Val accuracy: 0.275067\n",
      "Average loss: 2.006796, Train accuracy: 0.283725, Val accuracy: 0.298614\n",
      "Average loss: 1.990913, Train accuracy: 0.297051, Val accuracy: 0.300253\n",
      "Average loss: 1.987801, Train accuracy: 0.299099, Val accuracy: 0.302164\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Since it's so easy to add layers, let's add some!\n",
    "\n",
    "# TODO: Implement a model with 2 hidden layers of the size 100\n",
    "nn_model = nn.Sequential(\n",
    "            Flattener(),\n",
    "            nn.Linear(3*32*32, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 10), \n",
    "       )\n",
    "nn_model.type(torch.FloatTensor)\n",
    "\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr=1e-2, weight_decay=1e-1)\n",
    "loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте слой с Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.051332, Train accuracy: 0.313005, Val accuracy: 0.430278\n",
      "Average loss: 1.825193, Train accuracy: 0.427311, Val accuracy: 0.450140\n",
      "Average loss: 1.799908, Train accuracy: 0.439545, Val accuracy: 0.449799\n",
      "Average loss: 1.788122, Train accuracy: 0.446354, Val accuracy: 0.450345\n",
      "Average loss: 1.785177, Train accuracy: 0.446985, Val accuracy: 0.452665\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# We heard batch normalization is powerful, let's use it!\n",
    "# TODO: Add batch normalization after each of the hidden layers of the network, before or after non-linearity\n",
    "# Hint: check out torch.nn.BatchNorm1d\n",
    "\n",
    "nn_model = nn.Sequential(\n",
    "            Flattener(),\n",
    "            nn.Linear(3*32*32, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 10), \n",
    "         )\n",
    "\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr=1e-3, weight_decay=1e-1)\n",
    "loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте уменьшение скорости обучения по ходу тренировки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.070893, Train accuracy: 0.305447, Val accuracy: 0.419357\n",
      "Average loss: 1.867471, Train accuracy: 0.425929, Val accuracy: 0.441949\n",
      "Average loss: 1.843292, Train accuracy: 0.439955, Val accuracy: 0.456283\n",
      "Average loss: 1.830238, Train accuracy: 0.447940, Val accuracy: 0.457102\n",
      "Average loss: 1.827020, Train accuracy: 0.449015, Val accuracy: 0.458330\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Learning rate annealing\n",
    "# Reduce your learning rate 2x every 2 epochs\n",
    "# Hint: look up learning rate schedulers in PyTorch. You might need to extend train_model function a little bit too!\n",
    "\n",
    "nn_model = nn.Sequential(\n",
    "            Flattener(),\n",
    "            nn.Linear(3*32*32, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 10), \n",
    "         )\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr=1e-3, weight_decay=1e-1)\n",
    "loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализируем ошибки модели\n",
    "\n",
    "Попробуем посмотреть, на каких изображениях наша модель ошибается.\n",
    "Для этого мы получим все предсказания модели на validation set и сравним их с истинными метками (ground truth).\n",
    "\n",
    "Первая часть - реализовать код на PyTorch, который вычисляет все предсказания модели на validation set.  \n",
    "Чтобы это сделать мы приводим код `SubsetSampler`, который просто проходит по всем заданным индексам последовательно и составляет из них батчи. \n",
    "\n",
    "Реализуйте функцию `evaluate_model`, которая прогоняет модель через все сэмплы validation set и запоминает предсказания модели и истинные метки."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "Первая часть визуализации - вывести confusion matrix (https://en.wikipedia.org/wiki/Confusion_matrix ).\n",
    "\n",
    "Confusion matrix - это матрица, где каждой строке соответствуют классы предсказанный, а столбцу - классы истинных меток (ground truth). Число с координатами `i,j` - это количество сэмплов класса `j`, которые модель считает классом `i`.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Для того, чтобы облегчить вам задачу, ниже реализована функция `visualize_confusion_matrix` которая визуализирует такую матрицу.  \n",
    "Вам осталось реализовать функцию `build_confusion_matrix`, которая ее вычислит.\n",
    "\n",
    "Результатом должна быть матрица 10x10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class SubsetSampler(Sampler):\n",
    "    r\"\"\"Samples elements with given indices sequentially\n",
    "\n",
    "    Arguments:\n",
    "        indices (ndarray): indices of the samples to take\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, indices):\n",
    "        self.indices = indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in range(len(self.indices)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    \n",
    "def evaluate_model(model, dataset, indices):\n",
    "    \"\"\"\n",
    "    Computes predictions and ground truth labels for the indices of the dataset\n",
    "    \n",
    "    Returns: \n",
    "    predictions: np array of ints - model predictions\n",
    "    grount_truth: np array of ints - actual labels of the dataset\n",
    "    \"\"\"\n",
    "    model.eval() # Evaluation mode\n",
    "    \n",
    "    sampler = SubsetSampler(indices)\n",
    "    loader = torch.utils.data.DataLoader(dataset, sampler=sampler)\n",
    "    \n",
    "    predictions, ground_truth = [], []\n",
    "    for x, y in loader:\n",
    "        p_predictions = model(x)\n",
    "        p_indices = torch.argmax(p_predictions, dim=1)\n",
    "        predictions.append(p_indices)\n",
    "        ground_truth.append(y)\n",
    "    \n",
    "    # TODO: Evaluate model on the list of indices and capture predictions\n",
    "    # and ground truth labels\n",
    "    # Hint: SubsetSampler above could be useful!\n",
    "    \n",
    "    return predictions, ground_truth\n",
    "\n",
    "# Evaluate model on validation\n",
    "predictions, gt = evaluate_model(nn_model, data_train, val_indices)\n",
    "assert len(predictions) == len(val_indices)\n",
    "assert len(gt) == len(val_indices)\n",
    "assert gt[100] == data_train[val_indices[100]][1]\n",
    "assert np.any(np.not_equal(gt, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.52 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def visualize_confusion_matrix(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Visualizes confusion matrix\n",
    "    \n",
    "    confusion_matrix: np array of ints, x axis - predicted class, y axis - actual class\n",
    "                      [i][j] should have the count of samples that were predicted to be class i,\n",
    "                      but have j in the ground truth\n",
    "                     \n",
    "    \"\"\"\n",
    "    # Adapted from \n",
    "    # https://stackoverflow.com/questions/2897826/confusion-matrix-with-number-of-classified-misclassified-instances-on-it-python\n",
    "    assert confusion_matrix.shape[0] == confusion_matrix.shape[1]\n",
    "    size = confusion_matrix.shape[0]\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel(\"predicted\")\n",
    "    plt.xlabel(\"ground truth\")\n",
    "    res = plt.imshow(confusion_matrix, cmap='GnBu', interpolation='nearest')\n",
    "    cb = fig.colorbar(res)\n",
    "    plt.xticks(np.arange(size))\n",
    "    plt.yticks(np.arange(size))\n",
    "    for i, row in enumerate(confusion_matrix):\n",
    "        for j, count in enumerate(row):\n",
    "            plt.text(j, i, count, fontsize=14, horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "def build_confusion_matrix(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Builds confusion matrix from predictions and ground truth\n",
    "\n",
    "    predictions: np array of ints, model predictions for all validation samples\n",
    "    ground_truth: np array of ints, ground truth for all validation samples\n",
    "    \n",
    "    Returns:\n",
    "    np array of ints, (10,10), counts of samples for predicted/ground_truth classes\n",
    "    \"\"\"\n",
    "    \n",
    "#     confusion_matrix = np.zeros((10,10), np.int)\n",
    "    _confusion_matrix = confusion_matrix(ground_truth, predictions)\n",
    "    # TODO: Implement filling the prediction matrix\n",
    "    # np.array([[40, 2, 3], [10, 50,0], [0, 2, 80]])\n",
    "    \n",
    "    return _confusion_matrix\n",
    "\n",
    "confusion_matrix = build_confusion_matrix(predictions, gt)\n",
    "visualize_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, посмотрим на изображения, соответствующие некоторым элементам этой матрицы.\n",
    "\n",
    "Как и раньше, вам дана функция `visualize_images`, которой нужно воспрользоваться при реализации функции `visualize_predicted_actual`. Эта функция должна вывести несколько примеров, соответствующих заданному элементу матрицы.\n",
    "\n",
    "Визуализируйте наиболее частые ошибки и попробуйте понять, почему модель их совершает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x108 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x108 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train_images = dset.SVHN('./data/', split='train')\n",
    "\n",
    "def visualize_images(indices, data, title='', max_num=10):\n",
    "    \"\"\"\n",
    "    Visualizes several images from the dataset\n",
    " \n",
    "    indices: array of indices to visualize\n",
    "    data: torch Dataset with the images\n",
    "    title: string, title of the plot\n",
    "    max_num: int, max number of images to display\n",
    "    \"\"\"\n",
    "    to_show = min(len(indices), max_num)\n",
    "    fig = plt.figure(figsize=(10,1.5))\n",
    "    fig.suptitle(title)\n",
    "    for i, index in enumerate(indices[:to_show]):\n",
    "        plt.subplot(1,to_show, i+1)\n",
    "        plt.axis('off')\n",
    "        sample = data[index][0]\n",
    "        plt.imshow(sample)\n",
    "        \n",
    "def visualize_predicted_actual(predicted_class, gt_class, predictions, ground_truth, val_indices, data):\n",
    "    \"\"\"\n",
    "    Visualizes images of a ground truth class which were predicted as the other class \n",
    "    \n",
    "    predicted: int 0-9, index of the predicted class\n",
    "    gt_class: int 0-9, index of the ground truth class\n",
    "    predictions: np array of ints, model predictions for all validation samples\n",
    "    ground_truth: np array of ints, ground truth for all validation samples\n",
    "    val_indices: np array of ints, indices of validation samples\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement visualization using visualize_images above\n",
    "    # predictions and ground_truth are provided for validation set only, defined by val_indices\n",
    "    # Hint: numpy index arrays might be helpful\n",
    "    # https://docs.scipy.org/doc/numpy/user/basics.indexing.html#index-arrays\n",
    "    # Please make the title meaningful!\n",
    "    \n",
    "    indexes = val_indices[(predictions == predicted_class) & (ground_truth == gt_class)]\n",
    "    visualize_images(indexes, data, \"Classes that are predicted wrong\")\n",
    "\n",
    "visualize_predicted_actual(6, 8, predictions, gt, np.array(val_indices), data_train_images)\n",
    "visualize_predicted_actual(1, 7, predictions, gt, np.array(val_indices), data_train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переходим к свободным упражнениям!\n",
    "\n",
    "Натренируйте модель как можно лучше - экспериментируйте сами!\n",
    "Что следует обязательно попробовать:\n",
    "- перебор гиперпараметров с помощью валидационной выборки\n",
    "- другие оптимизаторы вместо SGD\n",
    "- изменение количества слоев и их размеров\n",
    "- наличие Batch Normalization\n",
    "\n",
    "Но ограничиваться этим не стоит!\n",
    "\n",
    "Точность на тестовой выборке должна быть доведена до **80%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Experiment here!\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = [1e-3, 1e-6]\n",
    "n_neurons_params = [100, 200]\n",
    "weight_decay_params = [1e-2, 1e-4]\n",
    "optimizer_params = [optim.SGD, optim.Adam, optim.RMSprop]\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = None\n",
    "best_optimizer = None\n",
    "best_val_accuracy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate=0.001, number of neurons=100, weight_decay=0.01, optimizer=SGD\n",
      "Average loss: 2.267290, Train accuracy: 0.163618, Val accuracy: 0.198348\n",
      "Average loss: 2.238345, Train accuracy: 0.196226, Val accuracy: 0.199236\n",
      "Average loss: 2.234885, Train accuracy: 0.197113, Val accuracy: 0.201147\n",
      "Average loss: 2.232999, Train accuracy: 0.197778, Val accuracy: 0.200874\n",
      "Average loss: 2.232662, Train accuracy: 0.197983, Val accuracy: 0.200737\n",
      "Average loss: 2.232497, Train accuracy: 0.198068, Val accuracy: 0.200669\n",
      "Average loss: 2.232445, Train accuracy: 0.198086, Val accuracy: 0.200601\n",
      "Average loss: 2.232440, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232416, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232409, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232433, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232438, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232438, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232429, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232429, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232431, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232445, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232444, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232445, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232441, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232434, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232445, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232451, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232425, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Average loss: 2.232450, Train accuracy: 0.198068, Val accuracy: 0.200601\n",
      "Val history: \n",
      "[tensor(0.1983, dtype=torch.float64), tensor(0.1992, dtype=torch.float64), tensor(0.2011, dtype=torch.float64), tensor(0.2009, dtype=torch.float64), tensor(0.2007, dtype=torch.float64), tensor(0.2007, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64), tensor(0.2006, dtype=torch.float64)]\n",
      "Average loss: 2.020969, Train accuracy: 0.325837, Val accuracy: 0.451027\n",
      "Average loss: 1.792199, Train accuracy: 0.458332, Val accuracy: 0.471845\n",
      "Average loss: 1.758388, Train accuracy: 0.473143, Val accuracy: 0.490001\n",
      "Average loss: 1.741413, Train accuracy: 0.481196, Val accuracy: 0.490205\n",
      "Average loss: 1.739020, Train accuracy: 0.482459, Val accuracy: 0.489318\n",
      "Average loss: 1.737605, Train accuracy: 0.483090, Val accuracy: 0.496963\n",
      "Average loss: 1.736093, Train accuracy: 0.484609, Val accuracy: 0.491571\n",
      "Average loss: 1.735596, Train accuracy: 0.485275, Val accuracy: 0.492799\n",
      "Average loss: 1.736124, Train accuracy: 0.484473, Val accuracy: 0.494369\n",
      "Average loss: 1.735283, Train accuracy: 0.483381, Val accuracy: 0.492458\n",
      "Average loss: 1.735450, Train accuracy: 0.484302, Val accuracy: 0.493891\n",
      "Average loss: 1.736336, Train accuracy: 0.483636, Val accuracy: 0.490137\n",
      "Average loss: 1.735141, Train accuracy: 0.485257, Val accuracy: 0.497372\n",
      "Average loss: 1.735688, Train accuracy: 0.484763, Val accuracy: 0.493755\n",
      "Average loss: 1.735695, Train accuracy: 0.483466, Val accuracy: 0.489523\n",
      "Average loss: 1.735046, Train accuracy: 0.485309, Val accuracy: 0.492253\n",
      "Average loss: 1.735810, Train accuracy: 0.485923, Val accuracy: 0.493686\n",
      "Average loss: 1.736271, Train accuracy: 0.483773, Val accuracy: 0.488431\n",
      "Average loss: 1.736589, Train accuracy: 0.483090, Val accuracy: 0.496621\n",
      "Average loss: 1.736092, Train accuracy: 0.482817, Val accuracy: 0.496212\n",
      "Average loss: 1.736001, Train accuracy: 0.484097, Val accuracy: 0.492458\n",
      "Average loss: 1.735488, Train accuracy: 0.484729, Val accuracy: 0.491775\n",
      "Average loss: 1.735194, Train accuracy: 0.485957, Val accuracy: 0.497509\n",
      "Average loss: 1.736210, Train accuracy: 0.485701, Val accuracy: 0.486724\n",
      "Average loss: 1.736038, Train accuracy: 0.483073, Val accuracy: 0.494642\n",
      "Val history: \n",
      "[tensor(0.4510, dtype=torch.float64), tensor(0.4718, dtype=torch.float64), tensor(0.4900, dtype=torch.float64), tensor(0.4902, dtype=torch.float64), tensor(0.4893, dtype=torch.float64), tensor(0.4970, dtype=torch.float64), tensor(0.4916, dtype=torch.float64), tensor(0.4928, dtype=torch.float64), tensor(0.4944, dtype=torch.float64), tensor(0.4925, dtype=torch.float64), tensor(0.4939, dtype=torch.float64), tensor(0.4901, dtype=torch.float64), tensor(0.4974, dtype=torch.float64), tensor(0.4938, dtype=torch.float64), tensor(0.4895, dtype=torch.float64), tensor(0.4923, dtype=torch.float64), tensor(0.4937, dtype=torch.float64), tensor(0.4884, dtype=torch.float64), tensor(0.4966, dtype=torch.float64), tensor(0.4962, dtype=torch.float64), tensor(0.4925, dtype=torch.float64), tensor(0.4918, dtype=torch.float64), tensor(0.4975, dtype=torch.float64), tensor(0.4867, dtype=torch.float64), tensor(0.4946, dtype=torch.float64)]\n",
      "learning rate=0.001, number of neurons=100, weight_decay=0.01, optimizer=Adam\n",
      "Average loss: 1.358311, Train accuracy: 0.561888, Val accuracy: 0.649990\n",
      "Average loss: 0.955694, Train accuracy: 0.723185, Val accuracy: 0.716402\n",
      "Average loss: 0.908353, Train accuracy: 0.736460, Val accuracy: 0.731349\n",
      "Average loss: 0.861775, Train accuracy: 0.754547, Val accuracy: 0.741519\n",
      "Average loss: 0.854028, Train accuracy: 0.757192, Val accuracy: 0.741929\n",
      "Average loss: 0.848122, Train accuracy: 0.759274, Val accuracy: 0.743635\n",
      "Average loss: 0.847295, Train accuracy: 0.759803, Val accuracy: 0.744113\n",
      "Average loss: 0.846560, Train accuracy: 0.759461, Val accuracy: 0.743772\n",
      "Average loss: 0.846465, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846381, Train accuracy: 0.759581, Val accuracy: 0.743772\n",
      "Average loss: 0.846420, Train accuracy: 0.759581, Val accuracy: 0.743772\n",
      "Average loss: 0.846474, Train accuracy: 0.759615, Val accuracy: 0.743772\n",
      "Average loss: 0.846427, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846409, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846366, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846406, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846371, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846457, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846401, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846399, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846386, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846446, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846381, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846431, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Average loss: 0.846413, Train accuracy: 0.759632, Val accuracy: 0.743772\n",
      "Val history: \n",
      "[tensor(0.6500, dtype=torch.float64), tensor(0.7164, dtype=torch.float64), tensor(0.7313, dtype=torch.float64), tensor(0.7415, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7436, dtype=torch.float64), tensor(0.7441, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64), tensor(0.7438, dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.483990, Train accuracy: 0.521585, Val accuracy: 0.618524\n",
      "Average loss: 1.067586, Train accuracy: 0.682865, Val accuracy: 0.714422\n",
      "Average loss: 0.977393, Train accuracy: 0.710917, Val accuracy: 0.730326\n",
      "Average loss: 0.902361, Train accuracy: 0.737638, Val accuracy: 0.752713\n",
      "Average loss: 0.879511, Train accuracy: 0.746084, Val accuracy: 0.757218\n",
      "Average loss: 0.869182, Train accuracy: 0.750537, Val accuracy: 0.759470\n",
      "Average loss: 0.861353, Train accuracy: 0.752466, Val accuracy: 0.759334\n",
      "Average loss: 0.863154, Train accuracy: 0.751834, Val accuracy: 0.758924\n",
      "Average loss: 0.863663, Train accuracy: 0.751442, Val accuracy: 0.761859\n",
      "Average loss: 0.861355, Train accuracy: 0.750384, Val accuracy: 0.757081\n",
      "Average loss: 0.862012, Train accuracy: 0.752005, Val accuracy: 0.762201\n",
      "Average loss: 0.864071, Train accuracy: 0.748524, Val accuracy: 0.760699\n",
      "Average loss: 0.864287, Train accuracy: 0.749804, Val accuracy: 0.756945\n",
      "Average loss: 0.864108, Train accuracy: 0.749923, Val accuracy: 0.761108\n",
      "Average loss: 0.861649, Train accuracy: 0.751988, Val accuracy: 0.760835\n",
      "Average loss: 0.862653, Train accuracy: 0.751903, Val accuracy: 0.760767\n",
      "Average loss: 0.861200, Train accuracy: 0.751271, Val accuracy: 0.762132\n",
      "Average loss: 0.864101, Train accuracy: 0.751408, Val accuracy: 0.758924\n",
      "Average loss: 0.862872, Train accuracy: 0.752346, Val accuracy: 0.756126\n",
      "Average loss: 0.864162, Train accuracy: 0.751664, Val accuracy: 0.757354\n",
      "Average loss: 0.862208, Train accuracy: 0.751135, Val accuracy: 0.758242\n",
      "Average loss: 0.862792, Train accuracy: 0.750230, Val accuracy: 0.759470\n",
      "Average loss: 0.862888, Train accuracy: 0.750623, Val accuracy: 0.760904\n",
      "Average loss: 0.863898, Train accuracy: 0.750247, Val accuracy: 0.759880\n",
      "Average loss: 0.861519, Train accuracy: 0.753302, Val accuracy: 0.758105\n",
      "Val history: \n",
      "[tensor(0.6185, dtype=torch.float64), tensor(0.7144, dtype=torch.float64), tensor(0.7303, dtype=torch.float64), tensor(0.7527, dtype=torch.float64), tensor(0.7572, dtype=torch.float64), tensor(0.7595, dtype=torch.float64), tensor(0.7593, dtype=torch.float64), tensor(0.7589, dtype=torch.float64), tensor(0.7619, dtype=torch.float64), tensor(0.7571, dtype=torch.float64), tensor(0.7622, dtype=torch.float64), tensor(0.7607, dtype=torch.float64), tensor(0.7569, dtype=torch.float64), tensor(0.7611, dtype=torch.float64), tensor(0.7608, dtype=torch.float64), tensor(0.7608, dtype=torch.float64), tensor(0.7621, dtype=torch.float64), tensor(0.7589, dtype=torch.float64), tensor(0.7561, dtype=torch.float64), tensor(0.7574, dtype=torch.float64), tensor(0.7582, dtype=torch.float64), tensor(0.7595, dtype=torch.float64), tensor(0.7609, dtype=torch.float64), tensor(0.7599, dtype=torch.float64), tensor(0.7581, dtype=torch.float64)]\n",
      "learning rate=0.001, number of neurons=100, weight_decay=0.01, optimizer=RMSprop\n",
      "Average loss: 1.472778, Train accuracy: 0.524554, Val accuracy: 0.609924\n",
      "Average loss: 1.001051, Train accuracy: 0.708938, Val accuracy: 0.709713\n",
      "Average loss: 0.941779, Train accuracy: 0.727707, Val accuracy: 0.724456\n",
      "Average loss: 0.893859, Train accuracy: 0.745077, Val accuracy: 0.733192\n",
      "Average loss: 0.885954, Train accuracy: 0.747807, Val accuracy: 0.733943\n",
      "Average loss: 0.880040, Train accuracy: 0.749940, Val accuracy: 0.735035\n",
      "Average loss: 0.879054, Train accuracy: 0.750589, Val accuracy: 0.734830\n",
      "Average loss: 0.878449, Train accuracy: 0.750879, Val accuracy: 0.734967\n",
      "Average loss: 0.878299, Train accuracy: 0.750845, Val accuracy: 0.735103\n",
      "Average loss: 0.878265, Train accuracy: 0.750896, Val accuracy: 0.735103\n",
      "Average loss: 0.878192, Train accuracy: 0.750879, Val accuracy: 0.735103\n",
      "Average loss: 0.878213, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878191, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878250, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878245, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878227, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878268, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878223, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878275, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878206, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878293, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878229, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878174, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878201, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Average loss: 0.878412, Train accuracy: 0.750913, Val accuracy: 0.735103\n",
      "Val history: \n",
      "[tensor(0.6099, dtype=torch.float64), tensor(0.7097, dtype=torch.float64), tensor(0.7245, dtype=torch.float64), tensor(0.7332, dtype=torch.float64), tensor(0.7339, dtype=torch.float64), tensor(0.7350, dtype=torch.float64), tensor(0.7348, dtype=torch.float64), tensor(0.7350, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64), tensor(0.7351, dtype=torch.float64)]\n",
      "Average loss: 1.545229, Train accuracy: 0.489711, Val accuracy: 0.504675\n",
      "Average loss: 1.091562, Train accuracy: 0.672798, Val accuracy: 0.715241\n",
      "Average loss: 0.968032, Train accuracy: 0.713033, Val accuracy: 0.726435\n",
      "Average loss: 0.875056, Train accuracy: 0.745606, Val accuracy: 0.758037\n",
      "Average loss: 0.856664, Train accuracy: 0.752141, Val accuracy: 0.767524\n",
      "Average loss: 0.838742, Train accuracy: 0.759171, Val accuracy: 0.766910\n",
      "Average loss: 0.839020, Train accuracy: 0.758881, Val accuracy: 0.768889\n",
      "Average loss: 0.835657, Train accuracy: 0.760263, Val accuracy: 0.770050\n",
      "Average loss: 0.838025, Train accuracy: 0.759257, Val accuracy: 0.767797\n",
      "Average loss: 0.836057, Train accuracy: 0.758045, Val accuracy: 0.767593\n",
      "Average loss: 0.837051, Train accuracy: 0.758352, Val accuracy: 0.769367\n",
      "Average loss: 0.837140, Train accuracy: 0.759120, Val accuracy: 0.769094\n",
      "Average loss: 0.837721, Train accuracy: 0.759206, Val accuracy: 0.769094\n",
      "Average loss: 0.836705, Train accuracy: 0.758574, Val accuracy: 0.769231\n",
      "Average loss: 0.835942, Train accuracy: 0.759888, Val accuracy: 0.771415\n",
      "Average loss: 0.835300, Train accuracy: 0.758062, Val accuracy: 0.769094\n",
      "Average loss: 0.835633, Train accuracy: 0.760263, Val accuracy: 0.770391\n",
      "Average loss: 0.837533, Train accuracy: 0.759632, Val accuracy: 0.768616\n",
      "Average loss: 0.840389, Train accuracy: 0.757892, Val accuracy: 0.767934\n",
      "Average loss: 0.840147, Train accuracy: 0.758574, Val accuracy: 0.769640\n",
      "Average loss: 0.837704, Train accuracy: 0.756868, Val accuracy: 0.768412\n",
      "Average loss: 0.837282, Train accuracy: 0.759120, Val accuracy: 0.767388\n",
      "Average loss: 0.836633, Train accuracy: 0.758096, Val accuracy: 0.768821\n",
      "Average loss: 0.835736, Train accuracy: 0.761492, Val accuracy: 0.767797\n",
      "Average loss: 0.836102, Train accuracy: 0.758489, Val accuracy: 0.767866\n",
      "Val history: \n",
      "[tensor(0.5047, dtype=torch.float64), tensor(0.7152, dtype=torch.float64), tensor(0.7264, dtype=torch.float64), tensor(0.7580, dtype=torch.float64), tensor(0.7675, dtype=torch.float64), tensor(0.7669, dtype=torch.float64), tensor(0.7689, dtype=torch.float64), tensor(0.7700, dtype=torch.float64), tensor(0.7678, dtype=torch.float64), tensor(0.7676, dtype=torch.float64), tensor(0.7694, dtype=torch.float64), tensor(0.7691, dtype=torch.float64), tensor(0.7691, dtype=torch.float64), tensor(0.7692, dtype=torch.float64), tensor(0.7714, dtype=torch.float64), tensor(0.7691, dtype=torch.float64), tensor(0.7704, dtype=torch.float64), tensor(0.7686, dtype=torch.float64), tensor(0.7679, dtype=torch.float64), tensor(0.7696, dtype=torch.float64), tensor(0.7684, dtype=torch.float64), tensor(0.7674, dtype=torch.float64), tensor(0.7688, dtype=torch.float64), tensor(0.7678, dtype=torch.float64), tensor(0.7679, dtype=torch.float64)]\n",
      "learning rate=0.001, number of neurons=100, weight_decay=0.0001, optimizer=SGD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.269173, Train accuracy: 0.160547, Val accuracy: 0.201761\n",
      "Average loss: 2.240366, Train accuracy: 0.199007, Val accuracy: 0.204901\n",
      "Average loss: 2.236927, Train accuracy: 0.201345, Val accuracy: 0.206948\n",
      "Average loss: 2.234988, Train accuracy: 0.202778, Val accuracy: 0.206880\n",
      "Average loss: 2.234649, Train accuracy: 0.202863, Val accuracy: 0.207426\n",
      "Average loss: 2.234462, Train accuracy: 0.202949, Val accuracy: 0.207426\n",
      "Average loss: 2.234406, Train accuracy: 0.202983, Val accuracy: 0.207426\n",
      "Average loss: 2.234379, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234380, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234403, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234401, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234375, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234399, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234415, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234403, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234393, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234393, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234396, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234417, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234387, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234402, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234387, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234390, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234423, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Average loss: 2.234406, Train accuracy: 0.203000, Val accuracy: 0.207426\n",
      "Val history: \n",
      "[tensor(0.2018, dtype=torch.float64), tensor(0.2049, dtype=torch.float64), tensor(0.2069, dtype=torch.float64), tensor(0.2069, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64), tensor(0.2074, dtype=torch.float64)]\n",
      "Average loss: 2.028498, Train accuracy: 0.326554, Val accuracy: 0.461675\n",
      "Average loss: 1.778574, Train accuracy: 0.466437, Val accuracy: 0.478943\n",
      "Average loss: 1.745646, Train accuracy: 0.483927, Val accuracy: 0.500921\n",
      "Average loss: 1.730519, Train accuracy: 0.491417, Val accuracy: 0.506177\n",
      "Average loss: 1.726405, Train accuracy: 0.493294, Val accuracy: 0.498260\n",
      "Average loss: 1.725140, Train accuracy: 0.495001, Val accuracy: 0.504812\n",
      "Average loss: 1.723244, Train accuracy: 0.496075, Val accuracy: 0.498191\n",
      "Average loss: 1.724132, Train accuracy: 0.495598, Val accuracy: 0.497645\n",
      "Average loss: 1.723681, Train accuracy: 0.494847, Val accuracy: 0.503174\n",
      "Average loss: 1.723684, Train accuracy: 0.494779, Val accuracy: 0.498396\n",
      "Average loss: 1.723014, Train accuracy: 0.495820, Val accuracy: 0.498055\n",
      "Average loss: 1.724215, Train accuracy: 0.495581, Val accuracy: 0.500648\n",
      "Average loss: 1.724283, Train accuracy: 0.494250, Val accuracy: 0.492799\n",
      "Average loss: 1.723930, Train accuracy: 0.495376, Val accuracy: 0.497577\n",
      "Average loss: 1.724264, Train accuracy: 0.493584, Val accuracy: 0.504675\n",
      "Average loss: 1.724409, Train accuracy: 0.495342, Val accuracy: 0.501331\n",
      "Average loss: 1.724196, Train accuracy: 0.493226, Val accuracy: 0.491707\n",
      "Average loss: 1.723593, Train accuracy: 0.494659, Val accuracy: 0.501126\n",
      "Average loss: 1.723379, Train accuracy: 0.494779, Val accuracy: 0.501536\n",
      "Average loss: 1.723133, Train accuracy: 0.495359, Val accuracy: 0.505904\n",
      "Average loss: 1.724868, Train accuracy: 0.493243, Val accuracy: 0.496007\n",
      "Average loss: 1.723222, Train accuracy: 0.493755, Val accuracy: 0.503106\n",
      "Average loss: 1.724464, Train accuracy: 0.495410, Val accuracy: 0.498328\n",
      "Average loss: 1.723321, Train accuracy: 0.497031, Val accuracy: 0.502150\n",
      "Average loss: 1.723248, Train accuracy: 0.495188, Val accuracy: 0.498874\n",
      "Val history: \n",
      "[tensor(0.4617, dtype=torch.float64), tensor(0.4789, dtype=torch.float64), tensor(0.5009, dtype=torch.float64), tensor(0.5062, dtype=torch.float64), tensor(0.4983, dtype=torch.float64), tensor(0.5048, dtype=torch.float64), tensor(0.4982, dtype=torch.float64), tensor(0.4976, dtype=torch.float64), tensor(0.5032, dtype=torch.float64), tensor(0.4984, dtype=torch.float64), tensor(0.4981, dtype=torch.float64), tensor(0.5006, dtype=torch.float64), tensor(0.4928, dtype=torch.float64), tensor(0.4976, dtype=torch.float64), tensor(0.5047, dtype=torch.float64), tensor(0.5013, dtype=torch.float64), tensor(0.4917, dtype=torch.float64), tensor(0.5011, dtype=torch.float64), tensor(0.5015, dtype=torch.float64), tensor(0.5059, dtype=torch.float64), tensor(0.4960, dtype=torch.float64), tensor(0.5031, dtype=torch.float64), tensor(0.4983, dtype=torch.float64), tensor(0.5022, dtype=torch.float64), tensor(0.4989, dtype=torch.float64)]\n",
      "learning rate=0.001, number of neurons=100, weight_decay=0.0001, optimizer=Adam\n",
      "Average loss: 1.229313, Train accuracy: 0.604358, Val accuracy: 0.679476\n",
      "Average loss: 0.789312, Train accuracy: 0.763147, Val accuracy: 0.755170\n",
      "Average loss: 0.737240, Train accuracy: 0.780688, Val accuracy: 0.765886\n",
      "Average loss: 0.699553, Train accuracy: 0.792223, Val accuracy: 0.772097\n",
      "Average loss: 0.693978, Train accuracy: 0.793997, Val accuracy: 0.773872\n",
      "Average loss: 0.689325, Train accuracy: 0.795260, Val accuracy: 0.774009\n",
      "Average loss: 0.688761, Train accuracy: 0.795652, Val accuracy: 0.774077\n",
      "Average loss: 0.688155, Train accuracy: 0.795959, Val accuracy: 0.774077\n",
      "Average loss: 0.688169, Train accuracy: 0.795977, Val accuracy: 0.774145\n",
      "Average loss: 0.688080, Train accuracy: 0.795994, Val accuracy: 0.774145\n",
      "Average loss: 0.688070, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688077, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688303, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688096, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688166, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688095, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688075, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688004, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688123, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688121, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688037, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688029, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688100, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688118, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Average loss: 0.688056, Train accuracy: 0.795977, Val accuracy: 0.774213\n",
      "Val history: \n",
      "[tensor(0.6795, dtype=torch.float64), tensor(0.7552, dtype=torch.float64), tensor(0.7659, dtype=torch.float64), tensor(0.7721, dtype=torch.float64), tensor(0.7739, dtype=torch.float64), tensor(0.7740, dtype=torch.float64), tensor(0.7741, dtype=torch.float64), tensor(0.7741, dtype=torch.float64), tensor(0.7741, dtype=torch.float64), tensor(0.7741, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64), tensor(0.7742, dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.338400, Train accuracy: 0.566256, Val accuracy: 0.702819\n",
      "Average loss: 0.880203, Train accuracy: 0.731000, Val accuracy: 0.752850\n",
      "Average loss: 0.819083, Train accuracy: 0.749104, Val accuracy: 0.769436\n",
      "Average loss: 0.775173, Train accuracy: 0.763403, Val accuracy: 0.770459\n",
      "Average loss: 0.769274, Train accuracy: 0.764461, Val accuracy: 0.772575\n",
      "Average loss: 0.766473, Train accuracy: 0.765519, Val accuracy: 0.770323\n",
      "Average loss: 0.761050, Train accuracy: 0.767191, Val accuracy: 0.772029\n",
      "Average loss: 0.764992, Train accuracy: 0.766440, Val accuracy: 0.772985\n",
      "Average loss: 0.764327, Train accuracy: 0.766764, Val accuracy: 0.773190\n",
      "Average loss: 0.762787, Train accuracy: 0.765860, Val accuracy: 0.772439\n",
      "Average loss: 0.764997, Train accuracy: 0.767089, Val accuracy: 0.772575\n",
      "Average loss: 0.763753, Train accuracy: 0.766116, Val accuracy: 0.773463\n",
      "Average loss: 0.760443, Train accuracy: 0.768061, Val accuracy: 0.772575\n",
      "Average loss: 0.763005, Train accuracy: 0.768334, Val accuracy: 0.772985\n",
      "Average loss: 0.765125, Train accuracy: 0.766372, Val accuracy: 0.772166\n",
      "Average loss: 0.765285, Train accuracy: 0.765860, Val accuracy: 0.774350\n",
      "Average loss: 0.765814, Train accuracy: 0.764597, Val accuracy: 0.773872\n",
      "Average loss: 0.761464, Train accuracy: 0.766901, Val accuracy: 0.773804\n",
      "Average loss: 0.764437, Train accuracy: 0.766048, Val accuracy: 0.771961\n",
      "Average loss: 0.766143, Train accuracy: 0.765280, Val accuracy: 0.772575\n",
      "Average loss: 0.764666, Train accuracy: 0.767020, Val accuracy: 0.772848\n",
      "Average loss: 0.762100, Train accuracy: 0.767447, Val accuracy: 0.771961\n",
      "Average loss: 0.762488, Train accuracy: 0.767038, Val accuracy: 0.773258\n",
      "Average loss: 0.763892, Train accuracy: 0.765945, Val accuracy: 0.773667\n",
      "Average loss: 0.761873, Train accuracy: 0.769495, Val accuracy: 0.772917\n",
      "Val history: \n",
      "[tensor(0.7028, dtype=torch.float64), tensor(0.7528, dtype=torch.float64), tensor(0.7694, dtype=torch.float64), tensor(0.7705, dtype=torch.float64), tensor(0.7726, dtype=torch.float64), tensor(0.7703, dtype=torch.float64), tensor(0.7720, dtype=torch.float64), tensor(0.7730, dtype=torch.float64), tensor(0.7732, dtype=torch.float64), tensor(0.7724, dtype=torch.float64), tensor(0.7726, dtype=torch.float64), tensor(0.7735, dtype=torch.float64), tensor(0.7726, dtype=torch.float64), tensor(0.7730, dtype=torch.float64), tensor(0.7722, dtype=torch.float64), tensor(0.7743, dtype=torch.float64), tensor(0.7739, dtype=torch.float64), tensor(0.7738, dtype=torch.float64), tensor(0.7720, dtype=torch.float64), tensor(0.7726, dtype=torch.float64), tensor(0.7728, dtype=torch.float64), tensor(0.7720, dtype=torch.float64), tensor(0.7733, dtype=torch.float64), tensor(0.7737, dtype=torch.float64), tensor(0.7729, dtype=torch.float64)]\n",
      "learning rate=0.001, number of neurons=100, weight_decay=0.0001, optimizer=RMSprop\n",
      "Average loss: 1.272565, Train accuracy: 0.595076, Val accuracy: 0.680431\n",
      "Average loss: 0.789317, Train accuracy: 0.765348, Val accuracy: 0.759129\n",
      "Average loss: 0.740426, Train accuracy: 0.779954, Val accuracy: 0.767593\n",
      "Average loss: 0.704679, Train accuracy: 0.791284, Val accuracy: 0.774077\n",
      "Average loss: 0.698899, Train accuracy: 0.792905, Val accuracy: 0.775237\n",
      "Average loss: 0.694327, Train accuracy: 0.794304, Val accuracy: 0.775578\n",
      "Average loss: 0.693800, Train accuracy: 0.794014, Val accuracy: 0.775305\n",
      "Average loss: 0.693440, Train accuracy: 0.794270, Val accuracy: 0.775374\n",
      "Average loss: 0.693358, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693265, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693254, Train accuracy: 0.794270, Val accuracy: 0.775442\n",
      "Average loss: 0.693188, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693172, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693239, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693201, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693223, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693187, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693332, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693188, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693150, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693241, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693230, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693212, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693242, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Average loss: 0.693255, Train accuracy: 0.794287, Val accuracy: 0.775442\n",
      "Val history: \n",
      "[tensor(0.6804, dtype=torch.float64), tensor(0.7591, dtype=torch.float64), tensor(0.7676, dtype=torch.float64), tensor(0.7741, dtype=torch.float64), tensor(0.7752, dtype=torch.float64), tensor(0.7756, dtype=torch.float64), tensor(0.7753, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64), tensor(0.7754, dtype=torch.float64)]\n",
      "Average loss: 1.309894, Train accuracy: 0.575419, Val accuracy: 0.683230\n",
      "Average loss: 0.875316, Train accuracy: 0.732280, Val accuracy: 0.755034\n",
      "Average loss: 0.814167, Train accuracy: 0.750793, Val accuracy: 0.764931\n",
      "Average loss: 0.776081, Train accuracy: 0.762277, Val accuracy: 0.772029\n",
      "Average loss: 0.769211, Train accuracy: 0.764649, Val accuracy: 0.774896\n",
      "Average loss: 0.764218, Train accuracy: 0.766952, Val accuracy: 0.772644\n",
      "Average loss: 0.765329, Train accuracy: 0.765195, Val accuracy: 0.774282\n",
      "Average loss: 0.764224, Train accuracy: 0.765843, Val accuracy: 0.773463\n",
      "Average loss: 0.762279, Train accuracy: 0.765604, Val accuracy: 0.774555\n",
      "Average loss: 0.764931, Train accuracy: 0.765690, Val accuracy: 0.773872\n",
      "Average loss: 0.764571, Train accuracy: 0.766236, Val accuracy: 0.772780\n",
      "Average loss: 0.764090, Train accuracy: 0.765638, Val accuracy: 0.772370\n",
      "Average loss: 0.763155, Train accuracy: 0.768078, Val accuracy: 0.771005\n",
      "Average loss: 0.763121, Train accuracy: 0.766952, Val accuracy: 0.774623\n",
      "Average loss: 0.764518, Train accuracy: 0.767293, Val accuracy: 0.775169\n",
      "Average loss: 0.762557, Train accuracy: 0.765451, Val accuracy: 0.772507\n",
      "Average loss: 0.763977, Train accuracy: 0.765758, Val accuracy: 0.772029\n",
      "Average loss: 0.761887, Train accuracy: 0.766952, Val accuracy: 0.772166\n",
      "Average loss: 0.765113, Train accuracy: 0.765980, Val accuracy: 0.772097\n",
      "Average loss: 0.762246, Train accuracy: 0.767771, Val accuracy: 0.773053\n",
      "Average loss: 0.764977, Train accuracy: 0.766099, Val accuracy: 0.773599\n",
      "Average loss: 0.763824, Train accuracy: 0.766082, Val accuracy: 0.772917\n",
      "Average loss: 0.763241, Train accuracy: 0.766321, Val accuracy: 0.773667\n",
      "Average loss: 0.765859, Train accuracy: 0.765178, Val accuracy: 0.772780\n",
      "Average loss: 0.763480, Train accuracy: 0.766935, Val accuracy: 0.769709\n",
      "Val history: \n",
      "[tensor(0.6832, dtype=torch.float64), tensor(0.7550, dtype=torch.float64), tensor(0.7649, dtype=torch.float64), tensor(0.7720, dtype=torch.float64), tensor(0.7749, dtype=torch.float64), tensor(0.7726, dtype=torch.float64), tensor(0.7743, dtype=torch.float64), tensor(0.7735, dtype=torch.float64), tensor(0.7746, dtype=torch.float64), tensor(0.7739, dtype=torch.float64), tensor(0.7728, dtype=torch.float64), tensor(0.7724, dtype=torch.float64), tensor(0.7710, dtype=torch.float64), tensor(0.7746, dtype=torch.float64), tensor(0.7752, dtype=torch.float64), tensor(0.7725, dtype=torch.float64), tensor(0.7720, dtype=torch.float64), tensor(0.7722, dtype=torch.float64), tensor(0.7721, dtype=torch.float64), tensor(0.7731, dtype=torch.float64), tensor(0.7736, dtype=torch.float64), tensor(0.7729, dtype=torch.float64), tensor(0.7737, dtype=torch.float64), tensor(0.7728, dtype=torch.float64), tensor(0.7697, dtype=torch.float64)]\n",
      "learning rate=0.001, number of neurons=200, weight_decay=0.01, optimizer=SGD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.261620, Train accuracy: 0.185851, Val accuracy: 0.206812\n",
      "Average loss: 2.235800, Train accuracy: 0.201805, Val accuracy: 0.206812\n",
      "Average loss: 2.232941, Train accuracy: 0.201993, Val accuracy: 0.206539\n",
      "Average loss: 2.231352, Train accuracy: 0.201754, Val accuracy: 0.206744\n",
      "Average loss: 2.231095, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230974, Train accuracy: 0.201754, Val accuracy: 0.206675\n",
      "Average loss: 2.230945, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230906, Train accuracy: 0.201754, Val accuracy: 0.206675\n",
      "Average loss: 2.230894, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230926, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230902, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230927, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230913, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230897, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230907, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230915, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230918, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230902, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230910, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230929, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230905, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230901, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230895, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230890, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Average loss: 2.230895, Train accuracy: 0.201771, Val accuracy: 0.206675\n",
      "Val history: \n",
      "[tensor(0.2068, dtype=torch.float64), tensor(0.2068, dtype=torch.float64), tensor(0.2065, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64), tensor(0.2067, dtype=torch.float64)]\n",
      "Average loss: 2.013896, Train accuracy: 0.330478, Val accuracy: 0.480650\n",
      "Average loss: 1.717934, Train accuracy: 0.483142, Val accuracy: 0.498942\n",
      "Average loss: 1.680491, Train accuracy: 0.502150, Val accuracy: 0.516074\n",
      "Average loss: 1.659949, Train accuracy: 0.509589, Val accuracy: 0.516961\n",
      "Average loss: 1.655671, Train accuracy: 0.511347, Val accuracy: 0.520784\n",
      "Average loss: 1.653834, Train accuracy: 0.512200, Val accuracy: 0.520647\n",
      "Average loss: 1.652981, Train accuracy: 0.513053, Val accuracy: 0.522695\n",
      "Average loss: 1.652648, Train accuracy: 0.514487, Val accuracy: 0.526107\n",
      "Average loss: 1.653125, Train accuracy: 0.512968, Val accuracy: 0.520442\n",
      "Average loss: 1.652930, Train accuracy: 0.512012, Val accuracy: 0.521261\n",
      "Average loss: 1.653257, Train accuracy: 0.512866, Val accuracy: 0.516825\n",
      "Average loss: 1.652572, Train accuracy: 0.513395, Val accuracy: 0.516279\n",
      "Average loss: 1.653186, Train accuracy: 0.513275, Val accuracy: 0.522149\n",
      "Average loss: 1.652466, Train accuracy: 0.514350, Val accuracy: 0.522080\n",
      "Average loss: 1.653083, Train accuracy: 0.514725, Val accuracy: 0.519282\n",
      "Average loss: 1.653347, Train accuracy: 0.512661, Val accuracy: 0.520033\n",
      "Average loss: 1.652858, Train accuracy: 0.513497, Val accuracy: 0.520374\n",
      "Average loss: 1.652430, Train accuracy: 0.514179, Val accuracy: 0.522626\n",
      "Average loss: 1.652914, Train accuracy: 0.513821, Val accuracy: 0.517507\n",
      "Average loss: 1.653060, Train accuracy: 0.511944, Val accuracy: 0.520101\n",
      "Average loss: 1.652068, Train accuracy: 0.513719, Val accuracy: 0.516688\n",
      "Average loss: 1.653111, Train accuracy: 0.515391, Val accuracy: 0.515528\n",
      "Average loss: 1.653215, Train accuracy: 0.514077, Val accuracy: 0.523582\n",
      "Average loss: 1.653169, Train accuracy: 0.514282, Val accuracy: 0.527746\n",
      "Average loss: 1.653459, Train accuracy: 0.512576, Val accuracy: 0.521261\n",
      "Val history: \n",
      "[tensor(0.4806, dtype=torch.float64), tensor(0.4989, dtype=torch.float64), tensor(0.5161, dtype=torch.float64), tensor(0.5170, dtype=torch.float64), tensor(0.5208, dtype=torch.float64), tensor(0.5206, dtype=torch.float64), tensor(0.5227, dtype=torch.float64), tensor(0.5261, dtype=torch.float64), tensor(0.5204, dtype=torch.float64), tensor(0.5213, dtype=torch.float64), tensor(0.5168, dtype=torch.float64), tensor(0.5163, dtype=torch.float64), tensor(0.5221, dtype=torch.float64), tensor(0.5221, dtype=torch.float64), tensor(0.5193, dtype=torch.float64), tensor(0.5200, dtype=torch.float64), tensor(0.5204, dtype=torch.float64), tensor(0.5226, dtype=torch.float64), tensor(0.5175, dtype=torch.float64), tensor(0.5201, dtype=torch.float64), tensor(0.5167, dtype=torch.float64), tensor(0.5155, dtype=torch.float64), tensor(0.5236, dtype=torch.float64), tensor(0.5277, dtype=torch.float64), tensor(0.5213, dtype=torch.float64)]\n",
      "learning rate=0.001, number of neurons=200, weight_decay=0.01, optimizer=Adam\n",
      "Average loss: 1.366037, Train accuracy: 0.554380, Val accuracy: 0.588902\n",
      "Average loss: 0.958387, Train accuracy: 0.718066, Val accuracy: 0.718040\n",
      "Average loss: 0.904278, Train accuracy: 0.735761, Val accuracy: 0.732237\n",
      "Average loss: 0.850319, Train accuracy: 0.756783, Val accuracy: 0.744864\n",
      "Average loss: 0.841623, Train accuracy: 0.759496, Val accuracy: 0.749027\n",
      "Average loss: 0.833964, Train accuracy: 0.762533, Val accuracy: 0.749778\n",
      "Average loss: 0.833016, Train accuracy: 0.763523, Val accuracy: 0.749983\n",
      "Average loss: 0.832093, Train accuracy: 0.764017, Val accuracy: 0.750870\n",
      "Average loss: 0.831960, Train accuracy: 0.764000, Val accuracy: 0.751007\n",
      "Average loss: 0.831875, Train accuracy: 0.763966, Val accuracy: 0.751075\n",
      "Average loss: 0.831809, Train accuracy: 0.763966, Val accuracy: 0.751075\n",
      "Average loss: 0.831845, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831841, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831913, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831868, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831858, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831834, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831875, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831844, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831828, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831844, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831905, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831914, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831846, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Average loss: 0.831905, Train accuracy: 0.763983, Val accuracy: 0.751007\n",
      "Val history: \n",
      "[tensor(0.5889, dtype=torch.float64), tensor(0.7180, dtype=torch.float64), tensor(0.7322, dtype=torch.float64), tensor(0.7449, dtype=torch.float64), tensor(0.7490, dtype=torch.float64), tensor(0.7498, dtype=torch.float64), tensor(0.7500, dtype=torch.float64), tensor(0.7509, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7511, dtype=torch.float64), tensor(0.7511, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64), tensor(0.7510, dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.452858, Train accuracy: 0.532795, Val accuracy: 0.630537\n",
      "Average loss: 1.028859, Train accuracy: 0.697130, Val accuracy: 0.721794\n",
      "Average loss: 0.919673, Train accuracy: 0.727383, Val accuracy: 0.752645\n",
      "Average loss: 0.827746, Train accuracy: 0.758591, Val accuracy: 0.771483\n",
      "Average loss: 0.809772, Train accuracy: 0.765041, Val accuracy: 0.777558\n",
      "Average loss: 0.792438, Train accuracy: 0.770945, Val accuracy: 0.778309\n",
      "Average loss: 0.787340, Train accuracy: 0.772737, Val accuracy: 0.778855\n",
      "Average loss: 0.788162, Train accuracy: 0.770979, Val accuracy: 0.779674\n",
      "Average loss: 0.788610, Train accuracy: 0.772208, Val accuracy: 0.780629\n",
      "Average loss: 0.786904, Train accuracy: 0.773692, Val accuracy: 0.780629\n",
      "Average loss: 0.789009, Train accuracy: 0.771508, Val accuracy: 0.779059\n",
      "Average loss: 0.785684, Train accuracy: 0.772890, Val accuracy: 0.777558\n",
      "Average loss: 0.785157, Train accuracy: 0.772464, Val accuracy: 0.779332\n",
      "Average loss: 0.785192, Train accuracy: 0.773812, Val accuracy: 0.778855\n",
      "Average loss: 0.785352, Train accuracy: 0.774255, Val accuracy: 0.779810\n",
      "Average loss: 0.785582, Train accuracy: 0.774102, Val accuracy: 0.780220\n",
      "Average loss: 0.788591, Train accuracy: 0.772293, Val accuracy: 0.777148\n",
      "Average loss: 0.788735, Train accuracy: 0.771918, Val accuracy: 0.777285\n",
      "Average loss: 0.787525, Train accuracy: 0.774255, Val accuracy: 0.781244\n",
      "Average loss: 0.787054, Train accuracy: 0.772293, Val accuracy: 0.778855\n",
      "Average loss: 0.787585, Train accuracy: 0.770843, Val accuracy: 0.779196\n",
      "Average loss: 0.787319, Train accuracy: 0.773436, Val accuracy: 0.778650\n",
      "Average loss: 0.787892, Train accuracy: 0.773829, Val accuracy: 0.777012\n",
      "Average loss: 0.785302, Train accuracy: 0.774733, Val accuracy: 0.778650\n",
      "Average loss: 0.787246, Train accuracy: 0.773948, Val accuracy: 0.780561\n",
      "Val history: \n",
      "[tensor(0.6305, dtype=torch.float64), tensor(0.7218, dtype=torch.float64), tensor(0.7526, dtype=torch.float64), tensor(0.7715, dtype=torch.float64), tensor(0.7776, dtype=torch.float64), tensor(0.7783, dtype=torch.float64), tensor(0.7789, dtype=torch.float64), tensor(0.7797, dtype=torch.float64), tensor(0.7806, dtype=torch.float64), tensor(0.7806, dtype=torch.float64), tensor(0.7791, dtype=torch.float64), tensor(0.7776, dtype=torch.float64), tensor(0.7793, dtype=torch.float64), tensor(0.7789, dtype=torch.float64), tensor(0.7798, dtype=torch.float64), tensor(0.7802, dtype=torch.float64), tensor(0.7771, dtype=torch.float64), tensor(0.7773, dtype=torch.float64), tensor(0.7812, dtype=torch.float64), tensor(0.7789, dtype=torch.float64), tensor(0.7792, dtype=torch.float64), tensor(0.7786, dtype=torch.float64), tensor(0.7770, dtype=torch.float64), tensor(0.7786, dtype=torch.float64), tensor(0.7806, dtype=torch.float64)]\n",
      "learning rate=0.001, number of neurons=200, weight_decay=0.01, optimizer=RMSprop\n",
      "Average loss: 1.575285, Train accuracy: 0.493789, Val accuracy: 0.538735\n",
      "Average loss: 1.025784, Train accuracy: 0.699451, Val accuracy: 0.707938\n",
      "Average loss: 0.946382, Train accuracy: 0.723612, Val accuracy: 0.720087\n",
      "Average loss: 0.880428, Train accuracy: 0.748319, Val accuracy: 0.735649\n",
      "Average loss: 0.868801, Train accuracy: 0.752807, Val accuracy: 0.740632\n",
      "Average loss: 0.860313, Train accuracy: 0.755571, Val accuracy: 0.741861\n",
      "Average loss: 0.859134, Train accuracy: 0.755725, Val accuracy: 0.742202\n",
      "Average loss: 0.858117, Train accuracy: 0.756117, Val accuracy: 0.741997\n",
      "Average loss: 0.858056, Train accuracy: 0.756117, Val accuracy: 0.741861\n",
      "Average loss: 0.857797, Train accuracy: 0.756083, Val accuracy: 0.741929\n",
      "Average loss: 0.857878, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857796, Train accuracy: 0.756015, Val accuracy: 0.741929\n",
      "Average loss: 0.857883, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857808, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857779, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857935, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857806, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857843, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857779, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857840, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857902, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857847, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857852, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857828, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Average loss: 0.857859, Train accuracy: 0.755998, Val accuracy: 0.741929\n",
      "Val history: \n",
      "[tensor(0.5387, dtype=torch.float64), tensor(0.7079, dtype=torch.float64), tensor(0.7201, dtype=torch.float64), tensor(0.7356, dtype=torch.float64), tensor(0.7406, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7422, dtype=torch.float64), tensor(0.7420, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64), tensor(0.7419, dtype=torch.float64)]\n",
      "Average loss: 1.541768, Train accuracy: 0.491571, Val accuracy: 0.572998\n",
      "Average loss: 1.050777, Train accuracy: 0.689179, Val accuracy: 0.737765\n",
      "Average loss: 0.906700, Train accuracy: 0.731717, Val accuracy: 0.757969\n",
      "Average loss: 0.796872, Train accuracy: 0.771354, Val accuracy: 0.786431\n",
      "Average loss: 0.779259, Train accuracy: 0.775211, Val accuracy: 0.791550\n",
      "Average loss: 0.763833, Train accuracy: 0.779494, Val accuracy: 0.793598\n",
      "Average loss: 0.760466, Train accuracy: 0.781234, Val accuracy: 0.791687\n",
      "Average loss: 0.760275, Train accuracy: 0.782684, Val accuracy: 0.791618\n",
      "Average loss: 0.758791, Train accuracy: 0.782360, Val accuracy: 0.791004\n",
      "Average loss: 0.758539, Train accuracy: 0.782667, Val accuracy: 0.788274\n",
      "Average loss: 0.758777, Train accuracy: 0.782821, Val accuracy: 0.792574\n",
      "Average loss: 0.759804, Train accuracy: 0.781797, Val accuracy: 0.792028\n",
      "Average loss: 0.758551, Train accuracy: 0.782360, Val accuracy: 0.789229\n",
      "Average loss: 0.758473, Train accuracy: 0.782974, Val accuracy: 0.790799\n",
      "Average loss: 0.757541, Train accuracy: 0.782974, Val accuracy: 0.790936\n",
      "Average loss: 0.757433, Train accuracy: 0.783128, Val accuracy: 0.790458\n",
      "Average loss: 0.759183, Train accuracy: 0.780824, Val accuracy: 0.790321\n",
      "Average loss: 0.759190, Train accuracy: 0.782360, Val accuracy: 0.792028\n",
      "Average loss: 0.760459, Train accuracy: 0.781814, Val accuracy: 0.791755\n",
      "Average loss: 0.759221, Train accuracy: 0.782241, Val accuracy: 0.791004\n",
      "Average loss: 0.756518, Train accuracy: 0.783111, Val accuracy: 0.793871\n",
      "Average loss: 0.759247, Train accuracy: 0.780210, Val accuracy: 0.791072\n",
      "Average loss: 0.759685, Train accuracy: 0.781405, Val accuracy: 0.792369\n",
      "Average loss: 0.757815, Train accuracy: 0.781882, Val accuracy: 0.790048\n",
      "Average loss: 0.759183, Train accuracy: 0.781644, Val accuracy: 0.792710\n",
      "Val history: \n",
      "[tensor(0.5730, dtype=torch.float64), tensor(0.7378, dtype=torch.float64), tensor(0.7580, dtype=torch.float64), tensor(0.7864, dtype=torch.float64), tensor(0.7916, dtype=torch.float64), tensor(0.7936, dtype=torch.float64), tensor(0.7917, dtype=torch.float64), tensor(0.7916, dtype=torch.float64), tensor(0.7910, dtype=torch.float64), tensor(0.7883, dtype=torch.float64), tensor(0.7926, dtype=torch.float64), tensor(0.7920, dtype=torch.float64), tensor(0.7892, dtype=torch.float64), tensor(0.7908, dtype=torch.float64), tensor(0.7909, dtype=torch.float64), tensor(0.7905, dtype=torch.float64), tensor(0.7903, dtype=torch.float64), tensor(0.7920, dtype=torch.float64), tensor(0.7918, dtype=torch.float64), tensor(0.7910, dtype=torch.float64), tensor(0.7939, dtype=torch.float64), tensor(0.7911, dtype=torch.float64), tensor(0.7924, dtype=torch.float64), tensor(0.7900, dtype=torch.float64), tensor(0.7927, dtype=torch.float64)]\n",
      "learning rate=0.001, number of neurons=200, weight_decay=0.0001, optimizer=SGD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.257658, Train accuracy: 0.172269, Val accuracy: 0.204286\n",
      "Average loss: 2.229105, Train accuracy: 0.198154, Val accuracy: 0.203604\n",
      "Average loss: 2.225819, Train accuracy: 0.198171, Val accuracy: 0.203126\n",
      "Average loss: 2.223907, Train accuracy: 0.197727, Val accuracy: 0.203126\n",
      "Average loss: 2.223565, Train accuracy: 0.197761, Val accuracy: 0.203126\n",
      "Average loss: 2.223395, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223361, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223330, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223332, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223334, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223368, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223330, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223348, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223344, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223344, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223338, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223362, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223341, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223345, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223310, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223335, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223351, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223345, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223343, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Average loss: 2.223331, Train accuracy: 0.197744, Val accuracy: 0.203126\n",
      "Val history: \n",
      "[tensor(0.2043, dtype=torch.float64), tensor(0.2036, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2031, dtype=torch.float64)]\n",
      "Average loss: 2.005606, Train accuracy: 0.325479, Val accuracy: 0.467886\n",
      "Average loss: 1.727866, Train accuracy: 0.473074, Val accuracy: 0.489250\n",
      "Average loss: 1.690979, Train accuracy: 0.491912, Val accuracy: 0.505836\n",
      "Average loss: 1.670357, Train accuracy: 0.500973, Val accuracy: 0.506860\n",
      "Average loss: 1.665039, Train accuracy: 0.503976, Val accuracy: 0.512388\n",
      "Average loss: 1.664575, Train accuracy: 0.503498, Val accuracy: 0.509863\n",
      "Average loss: 1.663709, Train accuracy: 0.504522, Val accuracy: 0.514436\n",
      "Average loss: 1.663561, Train accuracy: 0.503600, Val accuracy: 0.506928\n",
      "Average loss: 1.663634, Train accuracy: 0.504317, Val accuracy: 0.511364\n",
      "Average loss: 1.663729, Train accuracy: 0.503925, Val accuracy: 0.515528\n",
      "Average loss: 1.662635, Train accuracy: 0.503720, Val accuracy: 0.514026\n",
      "Average loss: 1.663480, Train accuracy: 0.504829, Val accuracy: 0.513753\n",
      "Average loss: 1.662776, Train accuracy: 0.504658, Val accuracy: 0.515118\n",
      "Average loss: 1.663839, Train accuracy: 0.505801, Val accuracy: 0.509317\n",
      "Average loss: 1.663357, Train accuracy: 0.503225, Val accuracy: 0.506860\n",
      "Average loss: 1.662561, Train accuracy: 0.505648, Val accuracy: 0.509112\n",
      "Average loss: 1.662799, Train accuracy: 0.506194, Val accuracy: 0.507679\n",
      "Average loss: 1.662570, Train accuracy: 0.506245, Val accuracy: 0.513071\n",
      "Average loss: 1.663196, Train accuracy: 0.504351, Val accuracy: 0.509795\n",
      "Average loss: 1.663624, Train accuracy: 0.504709, Val accuracy: 0.518599\n",
      "Average loss: 1.665185, Train accuracy: 0.504283, Val accuracy: 0.505017\n",
      "Average loss: 1.663326, Train accuracy: 0.503720, Val accuracy: 0.509385\n",
      "Average loss: 1.662387, Train accuracy: 0.505034, Val accuracy: 0.508566\n",
      "Average loss: 1.662306, Train accuracy: 0.504726, Val accuracy: 0.510068\n",
      "Average loss: 1.663170, Train accuracy: 0.504266, Val accuracy: 0.510545\n",
      "Val history: \n",
      "[tensor(0.4679, dtype=torch.float64), tensor(0.4892, dtype=torch.float64), tensor(0.5058, dtype=torch.float64), tensor(0.5069, dtype=torch.float64), tensor(0.5124, dtype=torch.float64), tensor(0.5099, dtype=torch.float64), tensor(0.5144, dtype=torch.float64), tensor(0.5069, dtype=torch.float64), tensor(0.5114, dtype=torch.float64), tensor(0.5155, dtype=torch.float64), tensor(0.5140, dtype=torch.float64), tensor(0.5138, dtype=torch.float64), tensor(0.5151, dtype=torch.float64), tensor(0.5093, dtype=torch.float64), tensor(0.5069, dtype=torch.float64), tensor(0.5091, dtype=torch.float64), tensor(0.5077, dtype=torch.float64), tensor(0.5131, dtype=torch.float64), tensor(0.5098, dtype=torch.float64), tensor(0.5186, dtype=torch.float64), tensor(0.5050, dtype=torch.float64), tensor(0.5094, dtype=torch.float64), tensor(0.5086, dtype=torch.float64), tensor(0.5101, dtype=torch.float64), tensor(0.5105, dtype=torch.float64)]\n",
      "learning rate=0.001, number of neurons=200, weight_decay=0.0001, optimizer=Adam\n",
      "Average loss: 1.196382, Train accuracy: 0.614698, Val accuracy: 0.701044\n",
      "Average loss: 0.734471, Train accuracy: 0.778965, Val accuracy: 0.777626\n",
      "Average loss: 0.673416, Train accuracy: 0.797922, Val accuracy: 0.784588\n",
      "Average loss: 0.625300, Train accuracy: 0.813876, Val accuracy: 0.794553\n",
      "Average loss: 0.617781, Train accuracy: 0.816265, Val accuracy: 0.794212\n",
      "Average loss: 0.611897, Train accuracy: 0.817647, Val accuracy: 0.794417\n",
      "Average loss: 0.611106, Train accuracy: 0.818295, Val accuracy: 0.794485\n",
      "Average loss: 0.610517, Train accuracy: 0.818688, Val accuracy: 0.794485\n",
      "Average loss: 0.610375, Train accuracy: 0.818619, Val accuracy: 0.794485\n",
      "Average loss: 0.610368, Train accuracy: 0.818619, Val accuracy: 0.794485\n",
      "Average loss: 0.610373, Train accuracy: 0.818636, Val accuracy: 0.794485\n",
      "Average loss: 0.610391, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610389, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610320, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610325, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610372, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610342, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610441, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610419, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610354, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610305, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610396, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610327, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610334, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Average loss: 0.610362, Train accuracy: 0.818602, Val accuracy: 0.794485\n",
      "Val history: \n",
      "[tensor(0.7010, dtype=torch.float64), tensor(0.7776, dtype=torch.float64), tensor(0.7846, dtype=torch.float64), tensor(0.7946, dtype=torch.float64), tensor(0.7942, dtype=torch.float64), tensor(0.7944, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64), tensor(0.7945, dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.284177, Train accuracy: 0.585077, Val accuracy: 0.709986\n",
      "Average loss: 0.811395, Train accuracy: 0.749480, Val accuracy: 0.770459\n",
      "Average loss: 0.747992, Train accuracy: 0.770382, Val accuracy: 0.783633\n",
      "Average loss: 0.702269, Train accuracy: 0.783913, Val accuracy: 0.788820\n",
      "Average loss: 0.691882, Train accuracy: 0.787974, Val accuracy: 0.788069\n",
      "Average loss: 0.687378, Train accuracy: 0.789527, Val accuracy: 0.789093\n",
      "Average loss: 0.685750, Train accuracy: 0.790226, Val accuracy: 0.788342\n",
      "Average loss: 0.685006, Train accuracy: 0.790090, Val accuracy: 0.790117\n",
      "Average loss: 0.683839, Train accuracy: 0.788981, Val accuracy: 0.790458\n",
      "Average loss: 0.685376, Train accuracy: 0.789851, Val accuracy: 0.791141\n",
      "Average loss: 0.687173, Train accuracy: 0.787974, Val accuracy: 0.790799\n",
      "Average loss: 0.687732, Train accuracy: 0.788708, Val accuracy: 0.790663\n",
      "Average loss: 0.686792, Train accuracy: 0.788691, Val accuracy: 0.789980\n",
      "Average loss: 0.684288, Train accuracy: 0.791523, Val accuracy: 0.789025\n",
      "Average loss: 0.687855, Train accuracy: 0.789595, Val accuracy: 0.790321\n",
      "Average loss: 0.684901, Train accuracy: 0.789390, Val accuracy: 0.787864\n",
      "Average loss: 0.686365, Train accuracy: 0.788315, Val accuracy: 0.789775\n",
      "Average loss: 0.685376, Train accuracy: 0.790585, Val accuracy: 0.791209\n",
      "Average loss: 0.686943, Train accuracy: 0.789083, Val accuracy: 0.788683\n",
      "Average loss: 0.687872, Train accuracy: 0.788878, Val accuracy: 0.790663\n",
      "Average loss: 0.687730, Train accuracy: 0.788110, Val accuracy: 0.790526\n",
      "Average loss: 0.687047, Train accuracy: 0.789424, Val accuracy: 0.790526\n",
      "Average loss: 0.684889, Train accuracy: 0.790653, Val accuracy: 0.788956\n",
      "Average loss: 0.685585, Train accuracy: 0.788691, Val accuracy: 0.790253\n",
      "Average loss: 0.688141, Train accuracy: 0.789885, Val accuracy: 0.789844\n",
      "Val history: \n",
      "[tensor(0.7100, dtype=torch.float64), tensor(0.7705, dtype=torch.float64), tensor(0.7836, dtype=torch.float64), tensor(0.7888, dtype=torch.float64), tensor(0.7881, dtype=torch.float64), tensor(0.7891, dtype=torch.float64), tensor(0.7883, dtype=torch.float64), tensor(0.7901, dtype=torch.float64), tensor(0.7905, dtype=torch.float64), tensor(0.7911, dtype=torch.float64), tensor(0.7908, dtype=torch.float64), tensor(0.7907, dtype=torch.float64), tensor(0.7900, dtype=torch.float64), tensor(0.7890, dtype=torch.float64), tensor(0.7903, dtype=torch.float64), tensor(0.7879, dtype=torch.float64), tensor(0.7898, dtype=torch.float64), tensor(0.7912, dtype=torch.float64), tensor(0.7887, dtype=torch.float64), tensor(0.7907, dtype=torch.float64), tensor(0.7905, dtype=torch.float64), tensor(0.7905, dtype=torch.float64), tensor(0.7890, dtype=torch.float64), tensor(0.7903, dtype=torch.float64), tensor(0.7898, dtype=torch.float64)]\n",
      "learning rate=0.001, number of neurons=200, weight_decay=0.0001, optimizer=RMSprop\n",
      "Average loss: 1.306441, Train accuracy: 0.595007, Val accuracy: 0.702478\n",
      "Average loss: 0.751063, Train accuracy: 0.773914, Val accuracy: 0.770391\n",
      "Average loss: 0.688041, Train accuracy: 0.793451, Val accuracy: 0.779605\n",
      "Average loss: 0.642324, Train accuracy: 0.809764, Val accuracy: 0.785680\n",
      "Average loss: 0.635189, Train accuracy: 0.810804, Val accuracy: 0.788001\n",
      "Average loss: 0.629237, Train accuracy: 0.813398, Val accuracy: 0.788274\n",
      "Average loss: 0.628660, Train accuracy: 0.813398, Val accuracy: 0.788342\n",
      "Average loss: 0.627933, Train accuracy: 0.813705, Val accuracy: 0.788479\n",
      "Average loss: 0.627921, Train accuracy: 0.813637, Val accuracy: 0.788410\n",
      "Average loss: 0.627899, Train accuracy: 0.813671, Val accuracy: 0.788479\n",
      "Average loss: 0.627838, Train accuracy: 0.813654, Val accuracy: 0.788479\n",
      "Average loss: 0.627786, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627812, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627960, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627811, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627822, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627793, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627780, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627807, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627791, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627908, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627866, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627804, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627776, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Average loss: 0.627858, Train accuracy: 0.813688, Val accuracy: 0.788479\n",
      "Val history: \n",
      "[tensor(0.7025, dtype=torch.float64), tensor(0.7704, dtype=torch.float64), tensor(0.7796, dtype=torch.float64), tensor(0.7857, dtype=torch.float64), tensor(0.7880, dtype=torch.float64), tensor(0.7883, dtype=torch.float64), tensor(0.7883, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7884, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64), tensor(0.7885, dtype=torch.float64)]\n",
      "Average loss: 1.252779, Train accuracy: 0.592977, Val accuracy: 0.718995\n",
      "Average loss: 0.784303, Train accuracy: 0.760997, Val accuracy: 0.777217\n",
      "Average loss: 0.715805, Train accuracy: 0.779357, Val accuracy: 0.790390\n",
      "Average loss: 0.678549, Train accuracy: 0.791523, Val accuracy: 0.794417\n",
      "Average loss: 0.671084, Train accuracy: 0.793963, Val accuracy: 0.793461\n",
      "Average loss: 0.665013, Train accuracy: 0.794390, Val accuracy: 0.795714\n",
      "Average loss: 0.665020, Train accuracy: 0.796983, Val accuracy: 0.797625\n",
      "Average loss: 0.661705, Train accuracy: 0.796198, Val accuracy: 0.797693\n",
      "Average loss: 0.664535, Train accuracy: 0.795977, Val accuracy: 0.796464\n",
      "Average loss: 0.665000, Train accuracy: 0.795959, Val accuracy: 0.795509\n",
      "Average loss: 0.667677, Train accuracy: 0.794902, Val accuracy: 0.795509\n",
      "Average loss: 0.664824, Train accuracy: 0.795874, Val accuracy: 0.794144\n",
      "Average loss: 0.664594, Train accuracy: 0.794714, Val accuracy: 0.796396\n",
      "Average loss: 0.663929, Train accuracy: 0.795789, Val accuracy: 0.796601\n",
      "Average loss: 0.666273, Train accuracy: 0.795550, Val accuracy: 0.797352\n",
      "Average loss: 0.665209, Train accuracy: 0.796864, Val accuracy: 0.795782\n",
      "Average loss: 0.665220, Train accuracy: 0.795806, Val accuracy: 0.796396\n",
      "Average loss: 0.663570, Train accuracy: 0.795072, Val accuracy: 0.796328\n",
      "Average loss: 0.667281, Train accuracy: 0.794390, Val accuracy: 0.796055\n",
      "Average loss: 0.664354, Train accuracy: 0.794970, Val accuracy: 0.794826\n",
      "Average loss: 0.663169, Train accuracy: 0.796642, Val accuracy: 0.798171\n",
      "Average loss: 0.665215, Train accuracy: 0.795994, Val accuracy: 0.796669\n",
      "Average loss: 0.664025, Train accuracy: 0.794987, Val accuracy: 0.796942\n",
      "Average loss: 0.663924, Train accuracy: 0.795601, Val accuracy: 0.797556\n",
      "Average loss: 0.666628, Train accuracy: 0.794799, Val accuracy: 0.793802\n",
      "Val history: \n",
      "[tensor(0.7190, dtype=torch.float64), tensor(0.7772, dtype=torch.float64), tensor(0.7904, dtype=torch.float64), tensor(0.7944, dtype=torch.float64), tensor(0.7935, dtype=torch.float64), tensor(0.7957, dtype=torch.float64), tensor(0.7976, dtype=torch.float64), tensor(0.7977, dtype=torch.float64), tensor(0.7965, dtype=torch.float64), tensor(0.7955, dtype=torch.float64), tensor(0.7955, dtype=torch.float64), tensor(0.7941, dtype=torch.float64), tensor(0.7964, dtype=torch.float64), tensor(0.7966, dtype=torch.float64), tensor(0.7974, dtype=torch.float64), tensor(0.7958, dtype=torch.float64), tensor(0.7964, dtype=torch.float64), tensor(0.7963, dtype=torch.float64), tensor(0.7961, dtype=torch.float64), tensor(0.7948, dtype=torch.float64), tensor(0.7982, dtype=torch.float64), tensor(0.7967, dtype=torch.float64), tensor(0.7969, dtype=torch.float64), tensor(0.7976, dtype=torch.float64), tensor(0.7938, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=100, weight_decay=0.01, optimizer=SGD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.306989, Train accuracy: 0.096082, Val accuracy: 0.094465\n",
      "Average loss: 2.306891, Train accuracy: 0.096219, Val accuracy: 0.094465\n",
      "Average loss: 2.306880, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306874, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306875, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306874, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306869, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306873, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306872, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306876, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306866, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306870, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306879, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306885, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306869, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306879, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306876, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306871, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306879, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306875, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306869, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306869, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306869, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306876, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Average loss: 2.306876, Train accuracy: 0.096253, Val accuracy: 0.094465\n",
      "Val history: \n",
      "[tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64), tensor(0.0945, dtype=torch.float64)]\n",
      "Average loss: 2.386121, Train accuracy: 0.082432, Val accuracy: 0.080541\n",
      "Average loss: 2.385391, Train accuracy: 0.082415, Val accuracy: 0.081087\n",
      "Average loss: 2.384761, Train accuracy: 0.084258, Val accuracy: 0.081223\n",
      "Average loss: 2.384820, Train accuracy: 0.084394, Val accuracy: 0.079858\n",
      "Average loss: 2.384483, Train accuracy: 0.084258, Val accuracy: 0.083066\n",
      "Average loss: 2.384998, Train accuracy: 0.083950, Val accuracy: 0.081564\n",
      "Average loss: 2.384801, Train accuracy: 0.082927, Val accuracy: 0.082110\n",
      "Average loss: 2.385001, Train accuracy: 0.083029, Val accuracy: 0.082042\n",
      "Average loss: 2.384385, Train accuracy: 0.084326, Val accuracy: 0.080745\n",
      "Average loss: 2.384971, Train accuracy: 0.084275, Val accuracy: 0.081087\n",
      "Average loss: 2.384467, Train accuracy: 0.083183, Val accuracy: 0.080609\n",
      "Average loss: 2.384734, Train accuracy: 0.084104, Val accuracy: 0.081428\n",
      "Average loss: 2.385286, Train accuracy: 0.083114, Val accuracy: 0.080541\n",
      "Average loss: 2.385056, Train accuracy: 0.083404, Val accuracy: 0.081906\n",
      "Average loss: 2.385636, Train accuracy: 0.083063, Val accuracy: 0.081087\n",
      "Average loss: 2.384074, Train accuracy: 0.084411, Val accuracy: 0.080131\n",
      "Average loss: 2.385294, Train accuracy: 0.082381, Val accuracy: 0.080541\n",
      "Average loss: 2.384667, Train accuracy: 0.083012, Val accuracy: 0.080268\n",
      "Average loss: 2.384856, Train accuracy: 0.083763, Val accuracy: 0.082179\n",
      "Average loss: 2.385118, Train accuracy: 0.083712, Val accuracy: 0.081291\n",
      "Average loss: 2.384958, Train accuracy: 0.083097, Val accuracy: 0.079995\n",
      "Average loss: 2.384450, Train accuracy: 0.083592, Val accuracy: 0.080199\n",
      "Average loss: 2.385321, Train accuracy: 0.083712, Val accuracy: 0.082452\n",
      "Average loss: 2.385399, Train accuracy: 0.083677, Val accuracy: 0.081428\n",
      "Average loss: 2.385405, Train accuracy: 0.083234, Val accuracy: 0.080882\n",
      "Val history: \n",
      "[tensor(0.0805, dtype=torch.float64), tensor(0.0811, dtype=torch.float64), tensor(0.0812, dtype=torch.float64), tensor(0.0799, dtype=torch.float64), tensor(0.0831, dtype=torch.float64), tensor(0.0816, dtype=torch.float64), tensor(0.0821, dtype=torch.float64), tensor(0.0820, dtype=torch.float64), tensor(0.0807, dtype=torch.float64), tensor(0.0811, dtype=torch.float64), tensor(0.0806, dtype=torch.float64), tensor(0.0814, dtype=torch.float64), tensor(0.0805, dtype=torch.float64), tensor(0.0819, dtype=torch.float64), tensor(0.0811, dtype=torch.float64), tensor(0.0801, dtype=torch.float64), tensor(0.0805, dtype=torch.float64), tensor(0.0803, dtype=torch.float64), tensor(0.0822, dtype=torch.float64), tensor(0.0813, dtype=torch.float64), tensor(0.0800, dtype=torch.float64), tensor(0.0802, dtype=torch.float64), tensor(0.0825, dtype=torch.float64), tensor(0.0814, dtype=torch.float64), tensor(0.0809, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=100, weight_decay=0.01, optimizer=Adam\n",
      "Average loss: 2.291558, Train accuracy: 0.135805, Val accuracy: 0.166815\n",
      "Average loss: 2.274021, Train accuracy: 0.168157, Val accuracy: 0.170364\n",
      "Average loss: 2.271767, Train accuracy: 0.169880, Val accuracy: 0.172889\n",
      "Average loss: 2.270574, Train accuracy: 0.170443, Val accuracy: 0.173435\n",
      "Average loss: 2.270371, Train accuracy: 0.170716, Val accuracy: 0.173435\n",
      "Average loss: 2.270246, Train accuracy: 0.170785, Val accuracy: 0.173504\n",
      "Average loss: 2.270248, Train accuracy: 0.170802, Val accuracy: 0.173435\n",
      "Average loss: 2.270232, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270223, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270234, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270229, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270234, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270240, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270243, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270197, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270218, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270220, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270235, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270220, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270225, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270234, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270233, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270228, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270244, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Average loss: 2.270216, Train accuracy: 0.170836, Val accuracy: 0.173435\n",
      "Val history: \n",
      "[tensor(0.1668, dtype=torch.float64), tensor(0.1704, dtype=torch.float64), tensor(0.1729, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1735, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1734, dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.391407, Train accuracy: 0.092857, Val accuracy: 0.100403\n",
      "Average loss: 2.350443, Train accuracy: 0.100894, Val accuracy: 0.103269\n",
      "Average loss: 2.344665, Train accuracy: 0.103965, Val accuracy: 0.103474\n",
      "Average loss: 2.340297, Train accuracy: 0.103931, Val accuracy: 0.104293\n",
      "Average loss: 2.340773, Train accuracy: 0.104102, Val accuracy: 0.104157\n",
      "Average loss: 2.340115, Train accuracy: 0.104887, Val accuracy: 0.105590\n",
      "Average loss: 2.339528, Train accuracy: 0.105689, Val accuracy: 0.103815\n",
      "Average loss: 2.339416, Train accuracy: 0.105484, Val accuracy: 0.104839\n",
      "Average loss: 2.339759, Train accuracy: 0.105313, Val accuracy: 0.104020\n",
      "Average loss: 2.340018, Train accuracy: 0.104665, Val accuracy: 0.104430\n",
      "Average loss: 2.339683, Train accuracy: 0.105621, Val accuracy: 0.104566\n",
      "Average loss: 2.339938, Train accuracy: 0.103744, Val accuracy: 0.105112\n",
      "Average loss: 2.339768, Train accuracy: 0.105399, Val accuracy: 0.103065\n",
      "Average loss: 2.339566, Train accuracy: 0.104802, Val accuracy: 0.104634\n",
      "Average loss: 2.339851, Train accuracy: 0.104767, Val accuracy: 0.104293\n",
      "Average loss: 2.339515, Train accuracy: 0.104341, Val accuracy: 0.105249\n",
      "Average loss: 2.339872, Train accuracy: 0.104307, Val accuracy: 0.102928\n",
      "Average loss: 2.339766, Train accuracy: 0.102993, Val accuracy: 0.103679\n",
      "Average loss: 2.340239, Train accuracy: 0.104784, Val accuracy: 0.103133\n",
      "Average loss: 2.339121, Train accuracy: 0.105160, Val accuracy: 0.102860\n",
      "Average loss: 2.339905, Train accuracy: 0.104307, Val accuracy: 0.103815\n",
      "Average loss: 2.339455, Train accuracy: 0.104733, Val accuracy: 0.104020\n",
      "Average loss: 2.339600, Train accuracy: 0.104597, Val accuracy: 0.103747\n",
      "Average loss: 2.340181, Train accuracy: 0.103812, Val accuracy: 0.104839\n",
      "Average loss: 2.339800, Train accuracy: 0.104238, Val accuracy: 0.104703\n",
      "Val history: \n",
      "[tensor(0.1004, dtype=torch.float64), tensor(0.1033, dtype=torch.float64), tensor(0.1035, dtype=torch.float64), tensor(0.1043, dtype=torch.float64), tensor(0.1042, dtype=torch.float64), tensor(0.1056, dtype=torch.float64), tensor(0.1038, dtype=torch.float64), tensor(0.1048, dtype=torch.float64), tensor(0.1040, dtype=torch.float64), tensor(0.1044, dtype=torch.float64), tensor(0.1046, dtype=torch.float64), tensor(0.1051, dtype=torch.float64), tensor(0.1031, dtype=torch.float64), tensor(0.1046, dtype=torch.float64), tensor(0.1043, dtype=torch.float64), tensor(0.1052, dtype=torch.float64), tensor(0.1029, dtype=torch.float64), tensor(0.1037, dtype=torch.float64), tensor(0.1031, dtype=torch.float64), tensor(0.1029, dtype=torch.float64), tensor(0.1038, dtype=torch.float64), tensor(0.1040, dtype=torch.float64), tensor(0.1037, dtype=torch.float64), tensor(0.1048, dtype=torch.float64), tensor(0.1047, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=100, weight_decay=0.01, optimizer=RMSprop\n",
      "Average loss: 2.298720, Train accuracy: 0.111729, Val accuracy: 0.149478\n",
      "Average loss: 2.284779, Train accuracy: 0.153244, Val accuracy: 0.155962\n",
      "Average loss: 2.282788, Train accuracy: 0.159694, Val accuracy: 0.160945\n",
      "Average loss: 2.281684, Train accuracy: 0.162458, Val accuracy: 0.161695\n",
      "Average loss: 2.281482, Train accuracy: 0.162799, Val accuracy: 0.162378\n",
      "Average loss: 2.281373, Train accuracy: 0.163089, Val accuracy: 0.162378\n",
      "Average loss: 2.281353, Train accuracy: 0.163140, Val accuracy: 0.162515\n",
      "Average loss: 2.281354, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281356, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281355, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281356, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281359, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281352, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281341, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281350, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281353, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281353, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281346, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281337, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281346, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281338, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281356, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281348, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281352, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Average loss: 2.281343, Train accuracy: 0.163123, Val accuracy: 0.162515\n",
      "Val history: \n",
      "[tensor(0.1495, dtype=torch.float64), tensor(0.1560, dtype=torch.float64), tensor(0.1609, dtype=torch.float64), tensor(0.1617, dtype=torch.float64), tensor(0.1624, dtype=torch.float64), tensor(0.1624, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64), tensor(0.1625, dtype=torch.float64)]\n",
      "Average loss: 2.288062, Train accuracy: 0.156452, Val accuracy: 0.179169\n",
      "Average loss: 2.251120, Train accuracy: 0.185442, Val accuracy: 0.185039\n",
      "Average loss: 2.245061, Train accuracy: 0.190356, Val accuracy: 0.191250\n",
      "Average loss: 2.241050, Train accuracy: 0.193018, Val accuracy: 0.190567\n",
      "Average loss: 2.241322, Train accuracy: 0.194963, Val accuracy: 0.194389\n",
      "Average loss: 2.240259, Train accuracy: 0.194315, Val accuracy: 0.192069\n",
      "Average loss: 2.240403, Train accuracy: 0.195799, Val accuracy: 0.192956\n",
      "Average loss: 2.240211, Train accuracy: 0.194741, Val accuracy: 0.191523\n",
      "Average loss: 2.240367, Train accuracy: 0.194246, Val accuracy: 0.193502\n",
      "Average loss: 2.240032, Train accuracy: 0.194127, Val accuracy: 0.193161\n",
      "Average loss: 2.240264, Train accuracy: 0.194656, Val accuracy: 0.191250\n",
      "Average loss: 2.240454, Train accuracy: 0.193103, Val accuracy: 0.190635\n",
      "Average loss: 2.240365, Train accuracy: 0.194622, Val accuracy: 0.190635\n",
      "Average loss: 2.240305, Train accuracy: 0.193769, Val accuracy: 0.189816\n",
      "Average loss: 2.240083, Train accuracy: 0.194912, Val accuracy: 0.191659\n",
      "Average loss: 2.240320, Train accuracy: 0.195253, Val accuracy: 0.190567\n",
      "Average loss: 2.240047, Train accuracy: 0.193973, Val accuracy: 0.190772\n",
      "Average loss: 2.239847, Train accuracy: 0.194775, Val accuracy: 0.192615\n",
      "Average loss: 2.240310, Train accuracy: 0.194997, Val accuracy: 0.191386\n",
      "Average loss: 2.240370, Train accuracy: 0.194775, Val accuracy: 0.190908\n",
      "Average loss: 2.239993, Train accuracy: 0.194025, Val accuracy: 0.190772\n",
      "Average loss: 2.240241, Train accuracy: 0.195970, Val accuracy: 0.192205\n",
      "Average loss: 2.240847, Train accuracy: 0.194195, Val accuracy: 0.191523\n",
      "Average loss: 2.240669, Train accuracy: 0.193103, Val accuracy: 0.191932\n",
      "Average loss: 2.240509, Train accuracy: 0.193956, Val accuracy: 0.191796\n",
      "Val history: \n",
      "[tensor(0.1792, dtype=torch.float64), tensor(0.1850, dtype=torch.float64), tensor(0.1912, dtype=torch.float64), tensor(0.1906, dtype=torch.float64), tensor(0.1944, dtype=torch.float64), tensor(0.1921, dtype=torch.float64), tensor(0.1930, dtype=torch.float64), tensor(0.1915, dtype=torch.float64), tensor(0.1935, dtype=torch.float64), tensor(0.1932, dtype=torch.float64), tensor(0.1912, dtype=torch.float64), tensor(0.1906, dtype=torch.float64), tensor(0.1906, dtype=torch.float64), tensor(0.1898, dtype=torch.float64), tensor(0.1917, dtype=torch.float64), tensor(0.1906, dtype=torch.float64), tensor(0.1908, dtype=torch.float64), tensor(0.1926, dtype=torch.float64), tensor(0.1914, dtype=torch.float64), tensor(0.1909, dtype=torch.float64), tensor(0.1908, dtype=torch.float64), tensor(0.1922, dtype=torch.float64), tensor(0.1915, dtype=torch.float64), tensor(0.1919, dtype=torch.float64), tensor(0.1918, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=100, weight_decay=0.0001, optimizer=SGD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.303806, Train accuracy: 0.082824, Val accuracy: 0.084226\n",
      "Average loss: 2.303727, Train accuracy: 0.082995, Val accuracy: 0.084226\n",
      "Average loss: 2.303721, Train accuracy: 0.083012, Val accuracy: 0.084158\n",
      "Average loss: 2.303718, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303717, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303719, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303716, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303715, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303715, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303707, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303717, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303724, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303718, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303708, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303715, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303718, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303716, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303716, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303716, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303712, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303709, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303719, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303720, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303710, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Average loss: 2.303721, Train accuracy: 0.083029, Val accuracy: 0.084158\n",
      "Val history: \n",
      "[tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64), tensor(0.0842, dtype=torch.float64)]\n",
      "Average loss: 2.343242, Train accuracy: 0.107037, Val accuracy: 0.109412\n",
      "Average loss: 2.342122, Train accuracy: 0.106013, Val accuracy: 0.109890\n",
      "Average loss: 2.340976, Train accuracy: 0.108248, Val accuracy: 0.109276\n",
      "Average loss: 2.342240, Train accuracy: 0.106627, Val accuracy: 0.107296\n",
      "Average loss: 2.342516, Train accuracy: 0.108487, Val accuracy: 0.109890\n",
      "Average loss: 2.341861, Train accuracy: 0.107941, Val accuracy: 0.107638\n",
      "Average loss: 2.341928, Train accuracy: 0.107276, Val accuracy: 0.108252\n",
      "Average loss: 2.342006, Train accuracy: 0.107139, Val accuracy: 0.108184\n",
      "Average loss: 2.342340, Train accuracy: 0.106747, Val accuracy: 0.108457\n",
      "Average loss: 2.342135, Train accuracy: 0.107924, Val accuracy: 0.106614\n",
      "Average loss: 2.342145, Train accuracy: 0.108112, Val accuracy: 0.109276\n",
      "Average loss: 2.342480, Train accuracy: 0.107122, Val accuracy: 0.109139\n",
      "Average loss: 2.341691, Train accuracy: 0.107515, Val accuracy: 0.109617\n",
      "Average loss: 2.341895, Train accuracy: 0.107276, Val accuracy: 0.108457\n",
      "Average loss: 2.342180, Train accuracy: 0.107156, Val accuracy: 0.107501\n",
      "Average loss: 2.342126, Train accuracy: 0.107480, Val accuracy: 0.109617\n",
      "Average loss: 2.342191, Train accuracy: 0.107378, Val accuracy: 0.111596\n",
      "Average loss: 2.342225, Train accuracy: 0.107498, Val accuracy: 0.108047\n",
      "Average loss: 2.341786, Train accuracy: 0.108078, Val accuracy: 0.108184\n",
      "Average loss: 2.342146, Train accuracy: 0.107736, Val accuracy: 0.109685\n",
      "Average loss: 2.342368, Train accuracy: 0.107498, Val accuracy: 0.107569\n",
      "Average loss: 2.341215, Train accuracy: 0.109255, Val accuracy: 0.111119\n",
      "Average loss: 2.341810, Train accuracy: 0.108897, Val accuracy: 0.106614\n",
      "Average loss: 2.342475, Train accuracy: 0.107719, Val accuracy: 0.109003\n",
      "Average loss: 2.342423, Train accuracy: 0.107634, Val accuracy: 0.108389\n",
      "Val history: \n",
      "[tensor(0.1094, dtype=torch.float64), tensor(0.1099, dtype=torch.float64), tensor(0.1093, dtype=torch.float64), tensor(0.1073, dtype=torch.float64), tensor(0.1099, dtype=torch.float64), tensor(0.1076, dtype=torch.float64), tensor(0.1083, dtype=torch.float64), tensor(0.1082, dtype=torch.float64), tensor(0.1085, dtype=torch.float64), tensor(0.1066, dtype=torch.float64), tensor(0.1093, dtype=torch.float64), tensor(0.1091, dtype=torch.float64), tensor(0.1096, dtype=torch.float64), tensor(0.1085, dtype=torch.float64), tensor(0.1075, dtype=torch.float64), tensor(0.1096, dtype=torch.float64), tensor(0.1116, dtype=torch.float64), tensor(0.1080, dtype=torch.float64), tensor(0.1082, dtype=torch.float64), tensor(0.1097, dtype=torch.float64), tensor(0.1076, dtype=torch.float64), tensor(0.1111, dtype=torch.float64), tensor(0.1066, dtype=torch.float64), tensor(0.1090, dtype=torch.float64), tensor(0.1084, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=100, weight_decay=0.0001, optimizer=Adam\n",
      "Average loss: 2.275723, Train accuracy: 0.148688, Val accuracy: 0.164562\n",
      "Average loss: 2.259343, Train accuracy: 0.170699, Val accuracy: 0.167975\n",
      "Average loss: 2.257179, Train accuracy: 0.172764, Val accuracy: 0.172753\n",
      "Average loss: 2.256008, Train accuracy: 0.174846, Val accuracy: 0.173299\n",
      "Average loss: 2.255801, Train accuracy: 0.175153, Val accuracy: 0.173913\n",
      "Average loss: 2.255710, Train accuracy: 0.175255, Val accuracy: 0.173981\n",
      "Average loss: 2.255680, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255677, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255688, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255669, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255689, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255670, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255688, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255666, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255663, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255664, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255685, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255695, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255682, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255658, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255680, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255699, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255683, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255677, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Average loss: 2.255678, Train accuracy: 0.175272, Val accuracy: 0.173981\n",
      "Val history: \n",
      "[tensor(0.1646, dtype=torch.float64), tensor(0.1680, dtype=torch.float64), tensor(0.1728, dtype=torch.float64), tensor(0.1733, dtype=torch.float64), tensor(0.1739, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64), tensor(0.1740, dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.317595, Train accuracy: 0.131045, Val accuracy: 0.144632\n",
      "Average loss: 2.278059, Train accuracy: 0.147289, Val accuracy: 0.151184\n",
      "Average loss: 2.272083, Train accuracy: 0.151657, Val accuracy: 0.152276\n",
      "Average loss: 2.269224, Train accuracy: 0.154148, Val accuracy: 0.152891\n",
      "Average loss: 2.268755, Train accuracy: 0.154916, Val accuracy: 0.155006\n",
      "Average loss: 2.268656, Train accuracy: 0.153619, Val accuracy: 0.158556\n",
      "Average loss: 2.268268, Train accuracy: 0.153005, Val accuracy: 0.154597\n",
      "Average loss: 2.268616, Train accuracy: 0.154387, Val accuracy: 0.153300\n",
      "Average loss: 2.268193, Train accuracy: 0.153790, Val accuracy: 0.154392\n",
      "Average loss: 2.268677, Train accuracy: 0.153466, Val accuracy: 0.154802\n",
      "Average loss: 2.268572, Train accuracy: 0.153483, Val accuracy: 0.152891\n",
      "Average loss: 2.268546, Train accuracy: 0.153193, Val accuracy: 0.151594\n",
      "Average loss: 2.268419, Train accuracy: 0.153994, Val accuracy: 0.151457\n",
      "Average loss: 2.268541, Train accuracy: 0.153739, Val accuracy: 0.152891\n",
      "Average loss: 2.268146, Train accuracy: 0.155189, Val accuracy: 0.152003\n",
      "Average loss: 2.268493, Train accuracy: 0.153909, Val accuracy: 0.155348\n",
      "Average loss: 2.268419, Train accuracy: 0.154012, Val accuracy: 0.152822\n",
      "Average loss: 2.268853, Train accuracy: 0.153244, Val accuracy: 0.152003\n",
      "Average loss: 2.268085, Train accuracy: 0.153807, Val accuracy: 0.154256\n",
      "Average loss: 2.268026, Train accuracy: 0.153124, Val accuracy: 0.152686\n",
      "Average loss: 2.268413, Train accuracy: 0.155206, Val accuracy: 0.155348\n",
      "Average loss: 2.269129, Train accuracy: 0.153090, Val accuracy: 0.154392\n",
      "Average loss: 2.267771, Train accuracy: 0.155394, Val accuracy: 0.153641\n",
      "Average loss: 2.268289, Train accuracy: 0.154762, Val accuracy: 0.152549\n",
      "Average loss: 2.268399, Train accuracy: 0.153721, Val accuracy: 0.154802\n",
      "Val history: \n",
      "[tensor(0.1446, dtype=torch.float64), tensor(0.1512, dtype=torch.float64), tensor(0.1523, dtype=torch.float64), tensor(0.1529, dtype=torch.float64), tensor(0.1550, dtype=torch.float64), tensor(0.1586, dtype=torch.float64), tensor(0.1546, dtype=torch.float64), tensor(0.1533, dtype=torch.float64), tensor(0.1544, dtype=torch.float64), tensor(0.1548, dtype=torch.float64), tensor(0.1529, dtype=torch.float64), tensor(0.1516, dtype=torch.float64), tensor(0.1515, dtype=torch.float64), tensor(0.1529, dtype=torch.float64), tensor(0.1520, dtype=torch.float64), tensor(0.1553, dtype=torch.float64), tensor(0.1528, dtype=torch.float64), tensor(0.1520, dtype=torch.float64), tensor(0.1543, dtype=torch.float64), tensor(0.1527, dtype=torch.float64), tensor(0.1553, dtype=torch.float64), tensor(0.1544, dtype=torch.float64), tensor(0.1536, dtype=torch.float64), tensor(0.1525, dtype=torch.float64), tensor(0.1548, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=100, weight_decay=0.0001, optimizer=RMSprop\n",
      "Average loss: 2.290078, Train accuracy: 0.135566, Val accuracy: 0.161286\n",
      "Average loss: 2.273909, Train accuracy: 0.158055, Val accuracy: 0.164084\n",
      "Average loss: 2.271679, Train accuracy: 0.160444, Val accuracy: 0.165927\n",
      "Average loss: 2.270469, Train accuracy: 0.162151, Val accuracy: 0.165859\n",
      "Average loss: 2.270248, Train accuracy: 0.162424, Val accuracy: 0.166200\n",
      "Average loss: 2.270130, Train accuracy: 0.162560, Val accuracy: 0.166200\n",
      "Average loss: 2.270119, Train accuracy: 0.162577, Val accuracy: 0.166269\n",
      "Average loss: 2.270102, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270111, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270104, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270102, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270108, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270108, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270103, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270111, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270103, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270103, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270105, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270119, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270103, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270107, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270111, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270106, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270101, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Average loss: 2.270114, Train accuracy: 0.162611, Val accuracy: 0.166337\n",
      "Val history: \n",
      "[tensor(0.1613, dtype=torch.float64), tensor(0.1641, dtype=torch.float64), tensor(0.1659, dtype=torch.float64), tensor(0.1659, dtype=torch.float64), tensor(0.1662, dtype=torch.float64), tensor(0.1662, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1663, dtype=torch.float64)]\n",
      "Average loss: 2.304040, Train accuracy: 0.135498, Val accuracy: 0.157873\n",
      "Average loss: 2.267511, Train accuracy: 0.162611, Val accuracy: 0.165108\n",
      "Average loss: 2.261583, Train accuracy: 0.168583, Val accuracy: 0.169203\n",
      "Average loss: 2.258481, Train accuracy: 0.170187, Val accuracy: 0.169203\n",
      "Average loss: 2.257936, Train accuracy: 0.170563, Val accuracy: 0.169750\n",
      "Average loss: 2.258528, Train accuracy: 0.171638, Val accuracy: 0.172411\n",
      "Average loss: 2.257993, Train accuracy: 0.172303, Val accuracy: 0.171934\n",
      "Average loss: 2.257934, Train accuracy: 0.171245, Val accuracy: 0.169135\n",
      "Average loss: 2.257402, Train accuracy: 0.170802, Val accuracy: 0.172207\n",
      "Average loss: 2.257212, Train accuracy: 0.170204, Val accuracy: 0.169203\n",
      "Average loss: 2.257375, Train accuracy: 0.170563, Val accuracy: 0.170091\n",
      "Average loss: 2.257935, Train accuracy: 0.170460, Val accuracy: 0.172275\n",
      "Average loss: 2.257481, Train accuracy: 0.171825, Val accuracy: 0.170227\n",
      "Average loss: 2.256853, Train accuracy: 0.172064, Val accuracy: 0.169818\n",
      "Average loss: 2.257467, Train accuracy: 0.172235, Val accuracy: 0.172275\n",
      "Average loss: 2.257731, Train accuracy: 0.170904, Val accuracy: 0.169750\n",
      "Average loss: 2.257661, Train accuracy: 0.171689, Val accuracy: 0.169681\n",
      "Average loss: 2.257570, Train accuracy: 0.171501, Val accuracy: 0.169886\n",
      "Average loss: 2.258149, Train accuracy: 0.170597, Val accuracy: 0.170637\n",
      "Average loss: 2.257707, Train accuracy: 0.171416, Val accuracy: 0.173435\n",
      "Average loss: 2.257478, Train accuracy: 0.170409, Val accuracy: 0.171661\n",
      "Average loss: 2.257362, Train accuracy: 0.171484, Val accuracy: 0.172070\n",
      "Average loss: 2.257465, Train accuracy: 0.170802, Val accuracy: 0.172070\n",
      "Average loss: 2.257837, Train accuracy: 0.171177, Val accuracy: 0.173504\n",
      "Average loss: 2.257861, Train accuracy: 0.171348, Val accuracy: 0.172138\n",
      "Val history: \n",
      "[tensor(0.1579, dtype=torch.float64), tensor(0.1651, dtype=torch.float64), tensor(0.1692, dtype=torch.float64), tensor(0.1692, dtype=torch.float64), tensor(0.1697, dtype=torch.float64), tensor(0.1724, dtype=torch.float64), tensor(0.1719, dtype=torch.float64), tensor(0.1691, dtype=torch.float64), tensor(0.1722, dtype=torch.float64), tensor(0.1692, dtype=torch.float64), tensor(0.1701, dtype=torch.float64), tensor(0.1723, dtype=torch.float64), tensor(0.1702, dtype=torch.float64), tensor(0.1698, dtype=torch.float64), tensor(0.1723, dtype=torch.float64), tensor(0.1697, dtype=torch.float64), tensor(0.1697, dtype=torch.float64), tensor(0.1699, dtype=torch.float64), tensor(0.1706, dtype=torch.float64), tensor(0.1734, dtype=torch.float64), tensor(0.1717, dtype=torch.float64), tensor(0.1721, dtype=torch.float64), tensor(0.1721, dtype=torch.float64), tensor(0.1735, dtype=torch.float64), tensor(0.1721, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=200, weight_decay=0.01, optimizer=SGD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.322844, Train accuracy: 0.078285, Val accuracy: 0.076104\n",
      "Average loss: 2.322727, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322713, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322711, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322711, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322693, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322711, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322709, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322718, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322713, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322715, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322705, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322706, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322711, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322711, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322705, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322711, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322705, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322712, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322706, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322714, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322713, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322715, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322712, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Average loss: 2.322711, Train accuracy: 0.078337, Val accuracy: 0.076104\n",
      "Val history: \n",
      "[tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64), tensor(0.0761, dtype=torch.float64)]\n",
      "Average loss: 2.451299, Train accuracy: 0.091578, Val accuracy: 0.092076\n",
      "Average loss: 2.450153, Train accuracy: 0.092840, Val accuracy: 0.092622\n",
      "Average loss: 2.450047, Train accuracy: 0.090776, Val accuracy: 0.092826\n",
      "Average loss: 2.449978, Train accuracy: 0.091407, Val accuracy: 0.093099\n",
      "Average loss: 2.450153, Train accuracy: 0.091851, Val accuracy: 0.092280\n",
      "Average loss: 2.450288, Train accuracy: 0.091936, Val accuracy: 0.092144\n",
      "Average loss: 2.449843, Train accuracy: 0.091765, Val accuracy: 0.092895\n",
      "Average loss: 2.449632, Train accuracy: 0.091236, Val accuracy: 0.093441\n",
      "Average loss: 2.449455, Train accuracy: 0.092175, Val accuracy: 0.091871\n",
      "Average loss: 2.449637, Train accuracy: 0.093182, Val accuracy: 0.092485\n",
      "Average loss: 2.449769, Train accuracy: 0.090895, Val accuracy: 0.092212\n",
      "Average loss: 2.449656, Train accuracy: 0.092072, Val accuracy: 0.093577\n",
      "Average loss: 2.449344, Train accuracy: 0.090315, Val accuracy: 0.092076\n",
      "Average loss: 2.449395, Train accuracy: 0.091799, Val accuracy: 0.091939\n",
      "Average loss: 2.449641, Train accuracy: 0.090178, Val accuracy: 0.093168\n",
      "Average loss: 2.449838, Train accuracy: 0.090895, Val accuracy: 0.092622\n",
      "Average loss: 2.449046, Train accuracy: 0.091799, Val accuracy: 0.093372\n",
      "Average loss: 2.449604, Train accuracy: 0.090776, Val accuracy: 0.093099\n",
      "Average loss: 2.449433, Train accuracy: 0.092619, Val accuracy: 0.091734\n",
      "Average loss: 2.448979, Train accuracy: 0.090417, Val accuracy: 0.093372\n",
      "Average loss: 2.449415, Train accuracy: 0.091851, Val accuracy: 0.092963\n",
      "Average loss: 2.449396, Train accuracy: 0.092055, Val accuracy: 0.093441\n",
      "Average loss: 2.449502, Train accuracy: 0.092636, Val accuracy: 0.092349\n",
      "Average loss: 2.449666, Train accuracy: 0.092516, Val accuracy: 0.092417\n",
      "Average loss: 2.450189, Train accuracy: 0.090110, Val accuracy: 0.093236\n",
      "Val history: \n",
      "[tensor(0.0921, dtype=torch.float64), tensor(0.0926, dtype=torch.float64), tensor(0.0928, dtype=torch.float64), tensor(0.0931, dtype=torch.float64), tensor(0.0923, dtype=torch.float64), tensor(0.0921, dtype=torch.float64), tensor(0.0929, dtype=torch.float64), tensor(0.0934, dtype=torch.float64), tensor(0.0919, dtype=torch.float64), tensor(0.0925, dtype=torch.float64), tensor(0.0922, dtype=torch.float64), tensor(0.0936, dtype=torch.float64), tensor(0.0921, dtype=torch.float64), tensor(0.0919, dtype=torch.float64), tensor(0.0932, dtype=torch.float64), tensor(0.0926, dtype=torch.float64), tensor(0.0934, dtype=torch.float64), tensor(0.0931, dtype=torch.float64), tensor(0.0917, dtype=torch.float64), tensor(0.0934, dtype=torch.float64), tensor(0.0930, dtype=torch.float64), tensor(0.0934, dtype=torch.float64), tensor(0.0923, dtype=torch.float64), tensor(0.0924, dtype=torch.float64), tensor(0.0932, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=200, weight_decay=0.01, optimizer=Adam\n",
      "Average loss: 2.269931, Train accuracy: 0.179094, Val accuracy: 0.194662\n",
      "Average loss: 2.251845, Train accuracy: 0.189503, Val accuracy: 0.195345\n",
      "Average loss: 2.249544, Train accuracy: 0.190100, Val accuracy: 0.195550\n",
      "Average loss: 2.248281, Train accuracy: 0.190305, Val accuracy: 0.195413\n",
      "Average loss: 2.248085, Train accuracy: 0.190373, Val accuracy: 0.195345\n",
      "Average loss: 2.247944, Train accuracy: 0.190390, Val accuracy: 0.195345\n",
      "Average loss: 2.247959, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247945, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247926, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247946, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247932, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247937, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247924, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247921, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247908, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247951, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247942, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247925, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247933, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247938, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247941, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247932, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247933, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247925, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Average loss: 2.247937, Train accuracy: 0.190407, Val accuracy: 0.195345\n",
      "Val history: \n",
      "[tensor(0.1947, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1955, dtype=torch.float64), tensor(0.1954, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64), tensor(0.1953, dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.283644, Train accuracy: 0.158124, Val accuracy: 0.202034\n",
      "Average loss: 2.227074, Train accuracy: 0.201754, Val accuracy: 0.208313\n",
      "Average loss: 2.218221, Train accuracy: 0.208050, Val accuracy: 0.217664\n",
      "Average loss: 2.212797, Train accuracy: 0.211736, Val accuracy: 0.217869\n",
      "Average loss: 2.211601, Train accuracy: 0.213869, Val accuracy: 0.217391\n",
      "Average loss: 2.212037, Train accuracy: 0.212930, Val accuracy: 0.218688\n",
      "Average loss: 2.211681, Train accuracy: 0.214927, Val accuracy: 0.217596\n",
      "Average loss: 2.211699, Train accuracy: 0.214278, Val accuracy: 0.217596\n",
      "Average loss: 2.211611, Train accuracy: 0.214261, Val accuracy: 0.216709\n",
      "Average loss: 2.211522, Train accuracy: 0.214961, Val accuracy: 0.218279\n",
      "Average loss: 2.211214, Train accuracy: 0.215405, Val accuracy: 0.218210\n",
      "Average loss: 2.211717, Train accuracy: 0.213340, Val accuracy: 0.219029\n",
      "Average loss: 2.211732, Train accuracy: 0.212589, Val accuracy: 0.216709\n",
      "Average loss: 2.211744, Train accuracy: 0.212794, Val accuracy: 0.218552\n",
      "Average loss: 2.211617, Train accuracy: 0.215012, Val accuracy: 0.220668\n",
      "Average loss: 2.212236, Train accuracy: 0.212504, Val accuracy: 0.218142\n",
      "Average loss: 2.211572, Train accuracy: 0.214739, Val accuracy: 0.216845\n",
      "Average loss: 2.211975, Train accuracy: 0.214091, Val accuracy: 0.218074\n",
      "Average loss: 2.211550, Train accuracy: 0.215183, Val accuracy: 0.216845\n",
      "Average loss: 2.212110, Train accuracy: 0.213801, Val accuracy: 0.218347\n",
      "Average loss: 2.212092, Train accuracy: 0.212521, Val accuracy: 0.219917\n",
      "Average loss: 2.211701, Train accuracy: 0.215183, Val accuracy: 0.217596\n",
      "Average loss: 2.211648, Train accuracy: 0.213954, Val accuracy: 0.217255\n",
      "Average loss: 2.212059, Train accuracy: 0.212777, Val accuracy: 0.218620\n",
      "Average loss: 2.211340, Train accuracy: 0.215183, Val accuracy: 0.214252\n",
      "Val history: \n",
      "[tensor(0.2020, dtype=torch.float64), tensor(0.2083, dtype=torch.float64), tensor(0.2177, dtype=torch.float64), tensor(0.2179, dtype=torch.float64), tensor(0.2174, dtype=torch.float64), tensor(0.2187, dtype=torch.float64), tensor(0.2176, dtype=torch.float64), tensor(0.2176, dtype=torch.float64), tensor(0.2167, dtype=torch.float64), tensor(0.2183, dtype=torch.float64), tensor(0.2182, dtype=torch.float64), tensor(0.2190, dtype=torch.float64), tensor(0.2167, dtype=torch.float64), tensor(0.2186, dtype=torch.float64), tensor(0.2207, dtype=torch.float64), tensor(0.2181, dtype=torch.float64), tensor(0.2168, dtype=torch.float64), tensor(0.2181, dtype=torch.float64), tensor(0.2168, dtype=torch.float64), tensor(0.2183, dtype=torch.float64), tensor(0.2199, dtype=torch.float64), tensor(0.2176, dtype=torch.float64), tensor(0.2173, dtype=torch.float64), tensor(0.2186, dtype=torch.float64), tensor(0.2143, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=200, weight_decay=0.01, optimizer=RMSprop\n",
      "Average loss: 2.268772, Train accuracy: 0.188530, Val accuracy: 0.201078\n",
      "Average loss: 2.250646, Train accuracy: 0.197522, Val accuracy: 0.201897\n",
      "Average loss: 2.248237, Train accuracy: 0.197983, Val accuracy: 0.201556\n",
      "Average loss: 2.246897, Train accuracy: 0.198068, Val accuracy: 0.201624\n",
      "Average loss: 2.246672, Train accuracy: 0.198086, Val accuracy: 0.201624\n",
      "Average loss: 2.246545, Train accuracy: 0.198137, Val accuracy: 0.201624\n",
      "Average loss: 2.246521, Train accuracy: 0.198137, Val accuracy: 0.201624\n",
      "Average loss: 2.246498, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246512, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246519, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246515, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246521, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246490, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246535, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246525, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246524, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246506, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246517, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246498, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246522, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246520, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246506, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246508, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246515, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Average loss: 2.246506, Train accuracy: 0.198154, Val accuracy: 0.201624\n",
      "Val history: \n",
      "[tensor(0.2011, dtype=torch.float64), tensor(0.2019, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64), tensor(0.2016, dtype=torch.float64)]\n",
      "Average loss: 2.261191, Train accuracy: 0.169198, Val accuracy: 0.207631\n",
      "Average loss: 2.204044, Train accuracy: 0.212777, Val accuracy: 0.218756\n",
      "Average loss: 2.195264, Train accuracy: 0.221308, Val accuracy: 0.223193\n",
      "Average loss: 2.189985, Train accuracy: 0.225045, Val accuracy: 0.225241\n",
      "Average loss: 2.188921, Train accuracy: 0.225830, Val accuracy: 0.224626\n",
      "Average loss: 2.188607, Train accuracy: 0.225932, Val accuracy: 0.227220\n",
      "Average loss: 2.188589, Train accuracy: 0.227690, Val accuracy: 0.224831\n",
      "Average loss: 2.188663, Train accuracy: 0.227844, Val accuracy: 0.227015\n",
      "Average loss: 2.188474, Train accuracy: 0.226871, Val accuracy: 0.226128\n",
      "Average loss: 2.188051, Train accuracy: 0.227724, Val accuracy: 0.227698\n",
      "Average loss: 2.188165, Train accuracy: 0.228748, Val accuracy: 0.227561\n",
      "Average loss: 2.188103, Train accuracy: 0.227741, Val accuracy: 0.229745\n",
      "Average loss: 2.188449, Train accuracy: 0.226120, Val accuracy: 0.225650\n",
      "Average loss: 2.187995, Train accuracy: 0.227383, Val accuracy: 0.226947\n",
      "Average loss: 2.188659, Train accuracy: 0.227605, Val accuracy: 0.225445\n",
      "Average loss: 2.188345, Train accuracy: 0.226496, Val accuracy: 0.228449\n",
      "Average loss: 2.188334, Train accuracy: 0.227161, Val accuracy: 0.225104\n",
      "Average loss: 2.188132, Train accuracy: 0.226973, Val accuracy: 0.225172\n",
      "Average loss: 2.188730, Train accuracy: 0.226359, Val accuracy: 0.223261\n",
      "Average loss: 2.188107, Train accuracy: 0.226973, Val accuracy: 0.226401\n",
      "Average loss: 2.188790, Train accuracy: 0.226666, Val accuracy: 0.228653\n",
      "Average loss: 2.187873, Train accuracy: 0.227212, Val accuracy: 0.224149\n",
      "Average loss: 2.188182, Train accuracy: 0.227229, Val accuracy: 0.228449\n",
      "Average loss: 2.188087, Train accuracy: 0.227042, Val accuracy: 0.227288\n",
      "Average loss: 2.188427, Train accuracy: 0.227349, Val accuracy: 0.225718\n",
      "Val history: \n",
      "[tensor(0.2076, dtype=torch.float64), tensor(0.2188, dtype=torch.float64), tensor(0.2232, dtype=torch.float64), tensor(0.2252, dtype=torch.float64), tensor(0.2246, dtype=torch.float64), tensor(0.2272, dtype=torch.float64), tensor(0.2248, dtype=torch.float64), tensor(0.2270, dtype=torch.float64), tensor(0.2261, dtype=torch.float64), tensor(0.2277, dtype=torch.float64), tensor(0.2276, dtype=torch.float64), tensor(0.2297, dtype=torch.float64), tensor(0.2257, dtype=torch.float64), tensor(0.2269, dtype=torch.float64), tensor(0.2254, dtype=torch.float64), tensor(0.2284, dtype=torch.float64), tensor(0.2251, dtype=torch.float64), tensor(0.2252, dtype=torch.float64), tensor(0.2233, dtype=torch.float64), tensor(0.2264, dtype=torch.float64), tensor(0.2287, dtype=torch.float64), tensor(0.2241, dtype=torch.float64), tensor(0.2284, dtype=torch.float64), tensor(0.2273, dtype=torch.float64), tensor(0.2257, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=200, weight_decay=0.0001, optimizer=SGD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.334382, Train accuracy: 0.072740, Val accuracy: 0.073442\n",
      "Average loss: 2.334214, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334208, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334197, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334201, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334188, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334203, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334195, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334196, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334191, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334188, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334196, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334201, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334196, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334199, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334201, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334188, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334197, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334187, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334192, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334188, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334194, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334189, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334194, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Average loss: 2.334186, Train accuracy: 0.072757, Val accuracy: 0.073442\n",
      "Val history: \n",
      "[tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64), tensor(0.0734, dtype=torch.float64)]\n",
      "Average loss: 2.341103, Train accuracy: 0.137529, Val accuracy: 0.135281\n",
      "Average loss: 2.339582, Train accuracy: 0.138774, Val accuracy: 0.140400\n",
      "Average loss: 2.339507, Train accuracy: 0.138655, Val accuracy: 0.139513\n",
      "Average loss: 2.339721, Train accuracy: 0.138126, Val accuracy: 0.137875\n",
      "Average loss: 2.339991, Train accuracy: 0.138638, Val accuracy: 0.140536\n",
      "Average loss: 2.340031, Train accuracy: 0.138109, Val accuracy: 0.140878\n",
      "Average loss: 2.339358, Train accuracy: 0.137512, Val accuracy: 0.137533\n",
      "Average loss: 2.340460, Train accuracy: 0.137887, Val accuracy: 0.140400\n",
      "Average loss: 2.339020, Train accuracy: 0.138604, Val accuracy: 0.139786\n",
      "Average loss: 2.339063, Train accuracy: 0.138484, Val accuracy: 0.136236\n",
      "Average loss: 2.339311, Train accuracy: 0.138569, Val accuracy: 0.140536\n",
      "Average loss: 2.339142, Train accuracy: 0.137119, Val accuracy: 0.139581\n",
      "Average loss: 2.339949, Train accuracy: 0.136334, Val accuracy: 0.137055\n",
      "Average loss: 2.340169, Train accuracy: 0.137375, Val accuracy: 0.139171\n",
      "Average loss: 2.339546, Train accuracy: 0.137273, Val accuracy: 0.137124\n",
      "Average loss: 2.339285, Train accuracy: 0.137921, Val accuracy: 0.143744\n",
      "Average loss: 2.339955, Train accuracy: 0.138450, Val accuracy: 0.139922\n",
      "Average loss: 2.340034, Train accuracy: 0.137580, Val accuracy: 0.139103\n",
      "Average loss: 2.340119, Train accuracy: 0.138023, Val accuracy: 0.141083\n",
      "Average loss: 2.339210, Train accuracy: 0.137716, Val accuracy: 0.139308\n",
      "Average loss: 2.339366, Train accuracy: 0.136727, Val accuracy: 0.136987\n",
      "Average loss: 2.339284, Train accuracy: 0.138194, Val accuracy: 0.139240\n",
      "Average loss: 2.339686, Train accuracy: 0.136607, Val accuracy: 0.139581\n",
      "Average loss: 2.339502, Train accuracy: 0.137631, Val accuracy: 0.138694\n",
      "Average loss: 2.339511, Train accuracy: 0.137870, Val accuracy: 0.138489\n",
      "Val history: \n",
      "[tensor(0.1353, dtype=torch.float64), tensor(0.1404, dtype=torch.float64), tensor(0.1395, dtype=torch.float64), tensor(0.1379, dtype=torch.float64), tensor(0.1405, dtype=torch.float64), tensor(0.1409, dtype=torch.float64), tensor(0.1375, dtype=torch.float64), tensor(0.1404, dtype=torch.float64), tensor(0.1398, dtype=torch.float64), tensor(0.1362, dtype=torch.float64), tensor(0.1405, dtype=torch.float64), tensor(0.1396, dtype=torch.float64), tensor(0.1371, dtype=torch.float64), tensor(0.1392, dtype=torch.float64), tensor(0.1371, dtype=torch.float64), tensor(0.1437, dtype=torch.float64), tensor(0.1399, dtype=torch.float64), tensor(0.1391, dtype=torch.float64), tensor(0.1411, dtype=torch.float64), tensor(0.1393, dtype=torch.float64), tensor(0.1370, dtype=torch.float64), tensor(0.1392, dtype=torch.float64), tensor(0.1396, dtype=torch.float64), tensor(0.1387, dtype=torch.float64), tensor(0.1385, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=200, weight_decay=0.0001, optimizer=Adam\n",
      "Average loss: 2.280645, Train accuracy: 0.163089, Val accuracy: 0.199986\n",
      "Average loss: 2.258396, Train accuracy: 0.196038, Val accuracy: 0.201420\n",
      "Average loss: 2.255543, Train accuracy: 0.197198, Val accuracy: 0.203058\n",
      "Average loss: 2.254002, Train accuracy: 0.197830, Val accuracy: 0.203399\n",
      "Average loss: 2.253723, Train accuracy: 0.197830, Val accuracy: 0.203467\n",
      "Average loss: 2.253609, Train accuracy: 0.197847, Val accuracy: 0.203467\n",
      "Average loss: 2.253596, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253570, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253568, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253560, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253561, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253586, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253586, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253567, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253571, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253586, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253574, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253572, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253567, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253561, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253572, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253572, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253568, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253564, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Average loss: 2.253564, Train accuracy: 0.197847, Val accuracy: 0.203536\n",
      "Val history: \n",
      "[tensor(0.2000, dtype=torch.float64), tensor(0.2014, dtype=torch.float64), tensor(0.2031, dtype=torch.float64), tensor(0.2034, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64), tensor(0.2035, dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.321979, Train accuracy: 0.111234, Val accuracy: 0.144973\n",
      "Average loss: 2.269911, Train accuracy: 0.154967, Val accuracy: 0.152413\n",
      "Average loss: 2.262320, Train accuracy: 0.162594, Val accuracy: 0.163607\n",
      "Average loss: 2.257394, Train accuracy: 0.166894, Val accuracy: 0.165108\n",
      "Average loss: 2.256907, Train accuracy: 0.167304, Val accuracy: 0.162583\n",
      "Average loss: 2.256110, Train accuracy: 0.168856, Val accuracy: 0.165176\n",
      "Average loss: 2.256312, Train accuracy: 0.168600, Val accuracy: 0.165449\n",
      "Average loss: 2.256038, Train accuracy: 0.169454, Val accuracy: 0.166746\n",
      "Average loss: 2.256363, Train accuracy: 0.168362, Val accuracy: 0.166951\n",
      "Average loss: 2.256249, Train accuracy: 0.167816, Val accuracy: 0.164153\n",
      "Average loss: 2.256470, Train accuracy: 0.169368, Val accuracy: 0.159511\n",
      "Average loss: 2.255747, Train accuracy: 0.169437, Val accuracy: 0.166815\n",
      "Average loss: 2.256330, Train accuracy: 0.168362, Val accuracy: 0.166337\n",
      "Average loss: 2.255875, Train accuracy: 0.169164, Val accuracy: 0.167497\n",
      "Average loss: 2.255990, Train accuracy: 0.169897, Val accuracy: 0.163061\n",
      "Average loss: 2.255758, Train accuracy: 0.169488, Val accuracy: 0.162924\n",
      "Average loss: 2.256162, Train accuracy: 0.168072, Val accuracy: 0.165040\n",
      "Average loss: 2.256341, Train accuracy: 0.167628, Val accuracy: 0.165927\n",
      "Average loss: 2.256196, Train accuracy: 0.169044, Val accuracy: 0.162924\n",
      "Average loss: 2.256291, Train accuracy: 0.168174, Val accuracy: 0.163197\n",
      "Average loss: 2.255884, Train accuracy: 0.168873, Val accuracy: 0.165791\n",
      "Average loss: 2.256523, Train accuracy: 0.168532, Val accuracy: 0.163948\n",
      "Average loss: 2.256112, Train accuracy: 0.169863, Val accuracy: 0.166473\n",
      "Average loss: 2.256293, Train accuracy: 0.168498, Val accuracy: 0.165791\n",
      "Average loss: 2.256459, Train accuracy: 0.167662, Val accuracy: 0.163607\n",
      "Val history: \n",
      "[tensor(0.1450, dtype=torch.float64), tensor(0.1524, dtype=torch.float64), tensor(0.1636, dtype=torch.float64), tensor(0.1651, dtype=torch.float64), tensor(0.1626, dtype=torch.float64), tensor(0.1652, dtype=torch.float64), tensor(0.1654, dtype=torch.float64), tensor(0.1667, dtype=torch.float64), tensor(0.1670, dtype=torch.float64), tensor(0.1642, dtype=torch.float64), tensor(0.1595, dtype=torch.float64), tensor(0.1668, dtype=torch.float64), tensor(0.1663, dtype=torch.float64), tensor(0.1675, dtype=torch.float64), tensor(0.1631, dtype=torch.float64), tensor(0.1629, dtype=torch.float64), tensor(0.1650, dtype=torch.float64), tensor(0.1659, dtype=torch.float64), tensor(0.1629, dtype=torch.float64), tensor(0.1632, dtype=torch.float64), tensor(0.1658, dtype=torch.float64), tensor(0.1639, dtype=torch.float64), tensor(0.1665, dtype=torch.float64), tensor(0.1658, dtype=torch.float64), tensor(0.1636, dtype=torch.float64)]\n",
      "learning rate=1e-06, number of neurons=200, weight_decay=0.0001, optimizer=RMSprop\n",
      "Average loss: 2.278677, Train accuracy: 0.184725, Val accuracy: 0.194048\n",
      "Average loss: 2.260103, Train accuracy: 0.188121, Val accuracy: 0.194321\n",
      "Average loss: 2.257503, Train accuracy: 0.188308, Val accuracy: 0.194458\n",
      "Average loss: 2.256081, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255856, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255726, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255686, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255689, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255677, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255653, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255672, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255674, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255687, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255670, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255661, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255671, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255668, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255670, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255651, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255681, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255684, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255665, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255679, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255669, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Average loss: 2.255673, Train accuracy: 0.188325, Val accuracy: 0.194526\n",
      "Val history: \n",
      "[tensor(0.1940, dtype=torch.float64), tensor(0.1943, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64), tensor(0.1945, dtype=torch.float64)]\n",
      "Average loss: 2.260876, Train accuracy: 0.176296, Val accuracy: 0.214866\n",
      "Average loss: 2.211320, Train accuracy: 0.214022, Val accuracy: 0.222101\n",
      "Average loss: 2.202600, Train accuracy: 0.218885, Val accuracy: 0.225036\n",
      "Average loss: 2.198891, Train accuracy: 0.223919, Val accuracy: 0.231930\n",
      "Average loss: 2.197750, Train accuracy: 0.223800, Val accuracy: 0.227630\n",
      "Average loss: 2.197510, Train accuracy: 0.223919, Val accuracy: 0.229131\n",
      "Average loss: 2.197983, Train accuracy: 0.222400, Val accuracy: 0.228722\n",
      "Average loss: 2.197666, Train accuracy: 0.223373, Val accuracy: 0.227425\n",
      "Average loss: 2.197249, Train accuracy: 0.223714, Val accuracy: 0.228176\n",
      "Average loss: 2.198022, Train accuracy: 0.224004, Val accuracy: 0.227630\n",
      "Average loss: 2.197389, Train accuracy: 0.224482, Val accuracy: 0.226810\n",
      "Average loss: 2.197638, Train accuracy: 0.224141, Val accuracy: 0.229404\n",
      "Average loss: 2.198141, Train accuracy: 0.223612, Val accuracy: 0.227903\n",
      "Average loss: 2.197456, Train accuracy: 0.224380, Val accuracy: 0.233226\n",
      "Average loss: 2.197462, Train accuracy: 0.223987, Val accuracy: 0.230087\n",
      "Average loss: 2.197938, Train accuracy: 0.222247, Val accuracy: 0.229404\n",
      "Average loss: 2.197260, Train accuracy: 0.224602, Val accuracy: 0.231315\n",
      "Average loss: 2.197614, Train accuracy: 0.223100, Val accuracy: 0.229882\n",
      "Average loss: 2.197473, Train accuracy: 0.224994, Val accuracy: 0.231315\n",
      "Average loss: 2.197707, Train accuracy: 0.223527, Val accuracy: 0.227083\n",
      "Average loss: 2.197671, Train accuracy: 0.224038, Val accuracy: 0.229199\n",
      "Average loss: 2.198060, Train accuracy: 0.223919, Val accuracy: 0.228517\n",
      "Average loss: 2.197736, Train accuracy: 0.223373, Val accuracy: 0.226810\n",
      "Average loss: 2.198034, Train accuracy: 0.222725, Val accuracy: 0.230155\n",
      "Average loss: 2.197539, Train accuracy: 0.223868, Val accuracy: 0.228449\n",
      "Val history: \n",
      "[tensor(0.2149, dtype=torch.float64), tensor(0.2221, dtype=torch.float64), tensor(0.2250, dtype=torch.float64), tensor(0.2319, dtype=torch.float64), tensor(0.2276, dtype=torch.float64), tensor(0.2291, dtype=torch.float64), tensor(0.2287, dtype=torch.float64), tensor(0.2274, dtype=torch.float64), tensor(0.2282, dtype=torch.float64), tensor(0.2276, dtype=torch.float64), tensor(0.2268, dtype=torch.float64), tensor(0.2294, dtype=torch.float64), tensor(0.2279, dtype=torch.float64), tensor(0.2332, dtype=torch.float64), tensor(0.2301, dtype=torch.float64), tensor(0.2294, dtype=torch.float64), tensor(0.2313, dtype=torch.float64), tensor(0.2299, dtype=torch.float64), tensor(0.2313, dtype=torch.float64), tensor(0.2271, dtype=torch.float64), tensor(0.2292, dtype=torch.float64), tensor(0.2285, dtype=torch.float64), tensor(0.2268, dtype=torch.float64), tensor(0.2302, dtype=torch.float64), tensor(0.2284, dtype=torch.float64)]\n",
      "Wall time: 10h 50min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for lr, n_neurons, weight_decay, nn_optimizer in itertools.product(\n",
    "                                                    lr_params,\n",
    "                                                    n_neurons_params,\n",
    "                                                    weight_decay_params,\n",
    "                                                    optimizer_params\n",
    "                                                ):\n",
    "    \n",
    "    print(f'learning rate={lr}, number of neurons={n_neurons}, weight_decay={weight_decay}, optimizer={nn_optimizer.__name__}')\n",
    "    \n",
    "    nn_models = [\n",
    "        nn.Sequential(\n",
    "                Flattener(),\n",
    "                nn.Linear(3*32*32, n_neurons),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(n_neurons, n_neurons),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(n_neurons, 10), \n",
    "           ),\n",
    "        nn.Sequential(\n",
    "                Flattener(),\n",
    "                nn.Linear(3*32*32, n_neurons),\n",
    "                nn.BatchNorm1d(n_neurons),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(n_neurons, n_neurons),\n",
    "                nn.BatchNorm1d(n_neurons),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(n_neurons, 10), \n",
    "             )\n",
    "    ]\n",
    "    \n",
    "    for nn_model in nn_models:\n",
    "        optimizer = nn_optimizer(nn_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, n_epochs)\n",
    "        accuracy = val_history[-1]\n",
    "        print(\"Val history: \")\n",
    "        print(val_history)\n",
    "        \n",
    "        if not best_val_accuracy or accuracy > best_val_accuracy:\n",
    "            best_classifier = nn_model\n",
    "            best_optimizer = optimizer\n",
    "            best_val_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flattener()\n",
      "  (1): Linear(in_features=3072, out_features=200, bias=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 1.0000000000000009e-15\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "tensor(0.7945, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(best_classifier)\n",
    "print(best_optimizer)\n",
    "print(best_val_accuracy)\n",
    "\n",
    "n_neurons = 200\n",
    "nn_model = nn.Sequential(\n",
    "                Flattener(),\n",
    "                nn.Linear(3*32*32, n_neurons),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(n_neurons, n_neurons),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(n_neurons, 10), \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.325541, Train accuracy: 0.590196, Val accuracy: 0.693605\n",
      "Average loss: 0.752423, Train accuracy: 0.773061, Val accuracy: 0.770323\n",
      "Average loss: 0.687730, Train accuracy: 0.793690, Val accuracy: 0.779742\n",
      "Average loss: 0.641641, Train accuracy: 0.808723, Val accuracy: 0.785475\n",
      "Average loss: 0.634357, Train accuracy: 0.811538, Val accuracy: 0.786021\n",
      "Average loss: 0.628772, Train accuracy: 0.813398, Val accuracy: 0.786977\n",
      "Average loss: 0.627803, Train accuracy: 0.813415, Val accuracy: 0.787864\n",
      "Average loss: 0.627254, Train accuracy: 0.813671, Val accuracy: 0.787933\n",
      "accuracy: tensor(0.7879, dtype=torch.float64)\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = nn_optimizer(nn_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 8)\n",
    "accuracy = val_history[-1]\n",
    "\n",
    "print(\"accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7619\n"
     ]
    }
   ],
   "source": [
    "# Как всегда, в конце проверяем на test set\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=batch_size)\n",
    "test_accuracy = compute_accuracy(nn_model, test_loader)\n",
    "print(\"Test accuracy: %2.4f\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
