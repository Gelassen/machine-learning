{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin dataset https://www.kaggle.com/a2015003713/militaryaircraftdetectiondataset\n",
    "import os\n",
    "import data_processor as dp\n",
    "import numpy as np\n",
    "# from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"input/archive_jets/dataset\"\n",
    "dataset = dp.TaskSpecificDataset(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pandas_dataset = dp.PandasDataset(dataset.get_features(), root)\n",
    "df = pandas_dataset.get_data_frame()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = df[\"class\"].unique()\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(target_labels)\n",
    "\n",
    "df[\"class\"] = df[\"class\"].apply(lambda x: le.transform([x])[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# TODO change array subset to full array size\n",
    "print(\"Dataset size: \" + str(len(df[\"filename\"])))\n",
    "images_as_bytes = dp.ImageDataset(root, df[\"filename\"][:100]).get_images()\n",
    "\n",
    "# len(images_as_bytes)\n",
    "print(images_as_bytes.shape)\n",
    "\n",
    "for idx in range(0,10):\n",
    "    plt.imshow(images_as_bytes[idx], interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change array subset to full array size\n",
    "X = images_as_bytes\n",
    "y = df[\"class\"][:100]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO have to skip it as issue with shpae (100,) instead of (100, 224, 224, 3) is still remain\n",
    "scalar = MinMaxScaler()\n",
    "# scalar.fit(x_train.reshape(x_train.shape[0],-1))\n",
    "# x_train = scalar.transform(x_train.reshape(x_train.shape[0], -1)).reshape(x_train.shape)\n",
    "# x_test = scalar.transform(x_test.reshape(x_test.shape[0], -1)).reshape(x_test.shape)\n",
    "# scalar.fit(x_train.reshape(x_train.shape[0],-1))\n",
    "# x_train = scalar.transform(x_train.reshape(x_train.shape[0],-1)).reshape(x_train.shape)\n",
    "# x_test = scalar.transform(x_test.reshape(x_test.shape[0], -1)).reshape(x_test.shape)\n",
    "x_train[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(data_shape_width, data_shape_height, data_shape_channel):\n",
    "\n",
    "    kernel_size = 3\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, (kernel_size), strides=(1,1), padding='valid',input_shape=(data_shape_width, data_shape_height, data_shape_channel)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (5, 5), activation=\"relu\", input_shape=(32, 32, 3)))\n",
    "\n",
    "    model.add(Conv2D(32, (kernel_size), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, (kernel_size), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, (kernel_size), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (kernel_size), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_cnn(x_train[0].shape[0], x_train[0].shape[1], x_train[0].shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize image close to the target resolution\n",
    "# do padding to meet with the target resolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\n",
    "    return lrate\n",
    "\n",
    "opt = Adam(lr=0.0001)\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=64, \n",
    "                    epochs=50, \n",
    "                    shuffle=True, \n",
    "                    verbose=2,\n",
    "                    validation_data=(x_test, y_test), \n",
    "                    callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
